<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs-rsses on Tokio</title>
    <link>http://aturon.github.io/private/tokio/docs/index.xml</link>
    <description>Recent content in Docs-rsses on Tokio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://aturon.github.io/private/tokio/docs/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>What is Tokio?</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/tokio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/tokio/</guid>
      <description>

&lt;h5 id=&#34;tokio-is-a-platform-for-writing-fast-networking-code-in-rust&#34;&gt;Tokio is a platform for writing fast networking code in Rust.&lt;/h5&gt;

&lt;p&gt;It&amp;rsquo;s broken into
several layers, with entry points based on your needs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The &lt;code&gt;tokio-proto&lt;/code&gt; layer is the easiest way to build servers and
clients&lt;/strong&gt;. All you have to do is handle message serialization; proto takes
care of the rest.  The library encompasses a wide range of protocol flavors,
including streaming and multiplexed protocols.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;The &lt;code&gt;tokio-core&lt;/code&gt; layer is good for writing specialized, low-level
asynchronous code&lt;/strong&gt;. It allows you to work directly with I/O objects and event
loops, but provides high-level, ergonomic APIs for doing so. Use &lt;code&gt;tokio-core&lt;/code&gt;
if your problem doesn&amp;rsquo;t fit into &lt;code&gt;tokio-proto&lt;/code&gt;, or you need absolute control
over the internals of your server or client.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;The &lt;code&gt;futures-rs&lt;/code&gt; layer provides abstractions like futures, streams and
sinks&lt;/strong&gt;, which are used throughout Tokio and the wider ecosystem. These
zero-cost abstractions are our approach for productive, asynchronous
programming in Rust.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Usually &lt;code&gt;tokio-proto&lt;/code&gt; is the right place to start, and that&amp;rsquo;s how we&amp;rsquo;ll start
with the guide as well.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example: an echo server using proto</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/simple-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/simple-server/</guid>
      <description>

&lt;p&gt;To kick off our tour of Tokio, we&amp;rsquo;ll build a simple line-based echo server using
&lt;code&gt;tokio-proto&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ cargo new --bin echo-proto
cd echo-proto
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll need to add dependencies on the Tokio stack:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]
futures = &amp;quot;0.1&amp;quot;
tokio-core = &amp;quot;0.1&amp;quot;
tokio-service = &amp;quot;0.1&amp;quot;
tokio-proto = &amp;quot;0.1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and bring them into scope in &lt;code&gt;main.rs&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;extern crate futures;
extern crate tokio_core;
extern crate tokio_proto;
extern crate tokio_service;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;A server in &lt;code&gt;tokio-proto&lt;/code&gt; is made up of three distinct parts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A &lt;strong&gt;codec&lt;/strong&gt;, which manages serialization of Rust request and response
types a protocol.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A &lt;strong&gt;protocol specification&lt;/strong&gt;, which puts together a codec and some basic
information about the protocol (is it multiplexed? streaming?).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A &lt;strong&gt;service&lt;/strong&gt;, which says how to produce a response given a request. A
service is basically an asynchronous function.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each part can vary independently, so once you&amp;rsquo;ve implemented a protocol
(like HTTP), you can pair it with a number different services.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see how it&amp;rsquo;s done.&lt;/p&gt;

&lt;h2 id=&#34;step-1-implement-a-codec&#34;&gt;Step 1: Implement a codec&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ll start by implementing a codec for a simple line-based protocol,
where messages are arbitrary byte sequences delimited by &lt;code&gt;&#39;\n&#39;&lt;/code&gt;. To do
this, we&amp;rsquo;ll need a couple of tools from &lt;code&gt;tokio-core&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use std::io;
use tokio_core::io::{Codec, EasyBuf};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In general, codecs may need local state, for example to record
information about incomplete decoding. We can get away without it,
though:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;pub struct LineCodec;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Codecs in Tokio implement the &lt;a href=&#34;TODO&#34;&gt;&lt;code&gt;Codec&lt;/code&gt; trait&lt;/a&gt;, which implements message
encoding and decoding. To start with, we&amp;rsquo;ll need to specify the message
type. &lt;code&gt;In&lt;/code&gt; gives the types of incoming messages &lt;em&gt;after decoding&lt;/em&gt;, while
&lt;code&gt;Out&lt;/code&gt; gives the type of outgoing messages &lt;em&gt;prior to encoding&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;impl Codec for LineCodec {
    type In = EasyBuf;
    type Out = io::Result&amp;lt;EasyBuf&amp;gt;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;a href=&#34;TODO&#34;&gt;&lt;code&gt;EasyBuf&lt;/code&gt; type&lt;/a&gt; used here provides simple but efficient buffer
management; you can think of it like &lt;code&gt;Arc&amp;lt;[u8]&amp;gt;&lt;/code&gt;, a reference-counted immutable
slice of bytes, with all the details handled for you. Outgoing messages from the
server use &lt;code&gt;Result&lt;/code&gt; in order to convey service errors on the Rust side.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;EasyBuf&lt;/code&gt; is in fact a &lt;a href=&#34;TODO&#34;&gt;built-in part of decoding&lt;/a&gt;: we are given
an input &lt;code&gt;EasyBuf&lt;/code&gt; that contains a chunk of unprocessed data, and we
must try to extract the first complete message, if there is one. If the
buffer doesn&amp;rsquo;t contain a complete message, we return &lt;code&gt;None&lt;/code&gt;, and the
server will automatically fetch more data before trying to decode again.&lt;/p&gt;

&lt;p&gt;For our line-based protocol, decoding is straightforward:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn decode(&amp;amp;mut self, buf: &amp;amp;mut EasyBuf) -&amp;gt; io::Result&amp;lt;Option&amp;lt;Self::In&amp;gt;&amp;gt; {
    if let Some(i) = buf.as_slice().iter().position(|&amp;amp;b| b == b&#39;\n&#39;) {
        // remove the line, including the &#39;\n&#39;, from the buffer
        let mut full_line = buf.drain_to(i + 1);

        // strip the `\n` from the returned buffer
        Ok(Some(full_line.drain_to(i)))
    } else {
        Ok(None)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;a href=&#34;TODO&#34;&gt;&lt;code&gt;drain&lt;/code&gt; method&lt;/a&gt; on &lt;code&gt;EasyBuf&lt;/code&gt; splits the buffer in two at the
given index, returning a new &lt;code&gt;EasyBuf&lt;/code&gt; instance corresponding to the
prefix ending at the index, and updating the existing &lt;code&gt;EasyBuf&lt;/code&gt; to
contain only the suffix. It&amp;rsquo;s the typical way to remove one complete
message from the input buffer.&lt;/p&gt;

&lt;p&gt;Encoding is even easier: you&amp;rsquo;re given mutable access to a &lt;code&gt;Vec&amp;lt;u8&amp;gt;&lt;/code&gt;,
into which you serialize your output data. To keep things simple,
we won&amp;rsquo;t provide support for error responses:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn encode(&amp;amp;mut self, item: io::Result&amp;lt;EasyBuf&amp;gt;, into: &amp;amp;mut Vec&amp;lt;u8&amp;gt;)
         -&amp;gt; io::Result&amp;lt;()&amp;gt;
{
    let item = item.expect(&amp;quot;Errors are not supported by this protocol&amp;quot;);
    into.extend(item.as_slice());
    into.push(b&#39;\n&#39;);
    Ok(())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that&amp;rsquo;s it for our codec.&lt;/p&gt;

&lt;h2 id=&#34;step-2-specify-the-protocol&#34;&gt;Step 2: Specify the protocol&lt;/h2&gt;

&lt;p&gt;Next, we turn the codec into a full-blown protocol. The &lt;code&gt;tokio-proto&lt;/code&gt; crate is
equipped to deal with a variety of protocol styles, including multiplexed and
streaming protocols. For our line-based protocol, though, we&amp;rsquo;ll use the simplest
style: a pipelined, non-streaming protocol:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use tokio_proto::pipeline::ServerProto;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As with codecs, protocols can carry state, typically used for configuration. We
don&amp;rsquo;t need any configuration, so we&amp;rsquo;ll make another unit struct:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;pub struct LineProto;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setting up a protocol requires just a bit of boilerplate, tying together our
chosen protocol style with the codec that we&amp;rsquo;ve built:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use tokio_core::io::{Io, Framed};

impl&amp;lt;T: Io + &#39;static&amp;gt; ServerProto&amp;lt;T&amp;gt; for LineProto {
    /// For this protocol style, `Request` matches the codec `In` type
    type Request = EasyBuf;

    /// For this protocol style, `Response` matches the successful arm of
    /// the codec `Out` type
    type Response = EasyBuf;

    /// For this protocol style, `Error` matches the erroneous arm of the
    /// codec `Out` type.
    type Error = io::Error;

    /// A bit of boilerplate to hook in the codec:
    type Transport = Framed&amp;lt;T, LineCodec&amp;gt;;
    type BindTransport = Result&amp;lt;Self::Transport, io::Error&amp;gt;;
    fn bind_transport(&amp;amp;self, io: T) -&amp;gt; Self::BindTransport {
        Ok(io.framed(LineCodec))
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;step-3-implement-a-service&#34;&gt;Step 3: Implement a service&lt;/h2&gt;

&lt;p&gt;At this point, we&amp;rsquo;ve built a generic line-based protocol. To actually &lt;em&gt;use&lt;/em&gt; this
protocol, we need to pair it with a &lt;em&gt;service&lt;/em&gt; that says how to respond to requests.
The &lt;code&gt;tokio-service&lt;/code&gt; crate provides a &lt;code&gt;Service&lt;/code&gt; trait for just this purpose:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use tokio_service::Service;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As with the other components we&amp;rsquo;ve built, in general a service may have data
associated with it. The service we want for this example just echos its input,
so no additional data is needed:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;pub struct Echo;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At its core, a service is an &lt;em&gt;asynchronous (non-blocking) function&lt;/em&gt; from
requests to responses.  We&amp;rsquo;ll have more to say about asynchronous programming in
the next guide; the only thing to know right now is that Tokio uses &lt;em&gt;futures&lt;/em&gt;
for asynchronous code, through the &lt;code&gt;Future&lt;/code&gt; trait. You can think of a future as
an asynchronous version of &lt;code&gt;Result&lt;/code&gt;. Let&amp;rsquo;s bring the basics into scope:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use futures::{future, Future, BoxFuture};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For our echo service, we don&amp;rsquo;t need to do any I/O to produce a response for a
request. So we use &lt;code&gt;future::ok&lt;/code&gt; to make a future that immediately returns a
value&amp;mdash;in this case, returning the request immediately back as a successful
response. To keep things simple, we&amp;rsquo;ll also box the future into a trait object,
which allows us to use the &lt;code&gt;BoxFuture&lt;/code&gt; trait to define our service, no matter
what future we actually use inside&amp;mdash;more on those tradeoffs later!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;impl Service for Echo {
    // These types must match the corresponding protocol types:
    type Request = EasyBuf;
    type Response = EasyBuf;
    type Error = io::Error;

    // The future for computing the response; box it for simplicity.
    type Future = BoxFuture&amp;lt;Self::Response, Self::Error&amp;gt;;

    // Produce a future for computing a response from a request.
    fn call(&amp;amp;mut self, req: Self::Request) -&amp;gt; Self::Future {
        // In this case, the response is immediate.
        future::ok(req).boxed()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;we-re-done-now-configure-and-run&#34;&gt;We&amp;rsquo;re done&amp;mdash;now configure and run!&lt;/h2&gt;

&lt;p&gt;With that, we have the ingredients necessary for a full-blown server: a general
protocol, and a particular service to provide on it. All that remains is to
actually configure and launch the server, which we&amp;rsquo;ll do using the &lt;code&gt;TcpServer&lt;/code&gt;
builder:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use tokio_proto::TcpServer;

fn main() {
    // Specify the localhost address
    let addr = &amp;quot;0.0.0.0:12345&amp;quot;.parse().unwrap();

    // The builder requires a protocol and an address
    let server = TcpServer::new(LineProto, addr);

    // We provide a way to *instantiate* the service for each new
    // connection; here, we just immediately return a new instance.
    server.serve(|| Ok(Echo));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can run this code and connect locally to try it out:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;~ $ telnet localhost 12345
Trying 127.0.0.1...
Connected to localhost.
Escape character is &#39;^]&#39;.
hello, world!
hello, world!
echo
echo
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;pairing-with-another-service&#34;&gt;Pairing with another service&lt;/h2&gt;

&lt;p&gt;That was a fair amount of ceremony for a simple echo server. But most of what we
did&amp;mdash;the protocol specification&amp;mdash;is reusable. To prove it, let&amp;rsquo;s build a
service that echos its input in reverse:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct EchoRev;

impl Service for EchoRev {
    type Request = EasyBuf;
    type Response = EasyBuf;
    type Error = io::Error;
    type Future = BoxFuture&amp;lt;Self::Response, Self::Error&amp;gt;;

    fn call(&amp;amp;mut self, req: Self::Request) -&amp;gt; Self::Future {
        let rev: Vec&amp;lt;u8&amp;gt; = req.as_slice().iter()
            .rev()
            .cloned()
            .collect();
        let resp = EasyBuf::from(rev);
        future::ok(resp).boxed()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not too shabby. And now, if we serve &lt;code&gt;EchoRev&lt;/code&gt; instead of &lt;code&gt;Echo&lt;/code&gt;, we&amp;rsquo;ll see:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;~ $ telnet localhost 12345
Trying 127.0.0.1...
Connected to localhost.
Escape character is &#39;^]&#39;.
hello, world!
!dlrow ,olleh
echo
ohce
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Futures</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/futures/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/futures/</guid>
      <description>

&lt;p&gt;Tokio is fundamentally based on &lt;em&gt;asynchronous I/O&lt;/em&gt;. While you don&amp;rsquo;t need to have
a deep understanding of async I/O to use Tokio, it&amp;rsquo;s good to have the basic picture.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with a simple piece of I/O you might want to perform: reading a
certain number of bytes from a socket. Rust&amp;rsquo;s standard library provides a
function,
&lt;a href=&#34;https://static.rust-lang.org/doc/master/std/io/trait.Read.html#method.read_exact&#34;&gt;&lt;code&gt;read_exact&lt;/code&gt;&lt;/a&gt;,
to do this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;// reads 4096 bytes into `my_vec`
socket.read_exact(&amp;amp;mut my_vec[..4096]);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Quick quiz&lt;/strong&gt;: what happens if the socket hasn&amp;rsquo;t received 4096 bytes yet?&lt;/p&gt;

&lt;p&gt;Since the standard library is based on &lt;em&gt;synchronous&lt;/em&gt; I/O, the answer is that the
calling thread is blocked, sleeping until more bytes are available. While that
works well in some contexts, it can be a problem for scaling up servers: if we
want to serve a large number of clients concurrently, but each request might
involve blocking a thread, then we&amp;rsquo;re going to need a large number of threads.&lt;/p&gt;

&lt;p&gt;In the asynchronous world, instead of blocking until requests can be completed,
we register that we &lt;em&gt;want&lt;/em&gt; to perform a certain request, and are later notified
when that request can be fulfilled. That means that we can use a single thread
to manage an arbitrary number of connections, with each connection using minimal
resources.&lt;/p&gt;

&lt;p&gt;Somehow, though, we&amp;rsquo;ve got to manage all of those in-flight requests. It&amp;rsquo;d be
nice if we could write code in terms of individual connections and operations,
and have all of that tracking and dispatching taken care of for us.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s where futures come in.&lt;/p&gt;

&lt;h2 id=&#34;futures&#34;&gt;Futures&lt;/h2&gt;

&lt;p&gt;A future is a value that&amp;rsquo;s in the process of being computed, but might not be
ready yet. Usually, the future becomes &lt;em&gt;complete&lt;/em&gt; (the value is ready) due to an
event happening somewhere else. While we&amp;rsquo;ve been looking at things from the
perspective of basic I/O, you can use a future to represent a wide range of
events, e.g.:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;A database query&lt;/strong&gt; that&amp;rsquo;s executing in a thread pool. When the query finishes,
the future is completed, and its value is the result of the query.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;An RPC invocation&lt;/strong&gt; to a server. When the server replies, the future is
completed, and its value is the server&amp;rsquo;s response.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;A timeout&lt;/strong&gt;. When time is up, the future is completed, and its value is
&lt;code&gt;()&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;A long-running CPU-intensive task&lt;/strong&gt;, running on a thread pool. When the task
finishes, the future is completed, and its value is the return value of the
task.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reading bytes from a socket&lt;/strong&gt;. When the bytes are ready, the future is completed
&amp;ndash; and depending on the buffering strategy, the bytes might be returned
directly, or written as a side-effect into some existing buffer.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In short, futures are applicable to asynchronous events of all shapes and
sizes. The asynchrony is reflected in the fact that you get a &lt;em&gt;future&lt;/em&gt; right
away, without blocking, even though the &lt;em&gt;value&lt;/em&gt; the future represents will
become ready only at some unknown time in the&amp;hellip; future.&lt;/p&gt;

&lt;h4 id=&#34;a-simple-example&#34;&gt;A simple example&lt;/h4&gt;

&lt;p&gt;Let&amp;rsquo;s make this concrete with an example: we&amp;rsquo;ll take a long-running computation
and add a timeout to it using futures.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;cargo new --bin prime-timeout
cd prime-timeout
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we&amp;rsquo;ll bring in futures and a couple additional tools on top:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-toml&#34;&gt;[dependencies]
futures = &amp;quot;0.1.7&amp;quot;
futures-cpupool = &amp;quot;0.1.2&amp;quot;
tokio-timer = { git = &amp;quot;https://github.com/tokio-rs/tokio-timer&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For our lengthy computation, we&amp;rsquo;ll inefficiently confirm that a large prime
number is prime:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;CONST BIG_PRIME: u64 = 15485867;

// checks whether a number is prime, slowly
fn is_prime(num: u64) -&amp;gt; bool {
    for i in 2..num {
        if i % num == 0 { return false }
    }
    true
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;synchronous-version&#34;&gt;Synchronous version&lt;/h5&gt;

&lt;p&gt;Before we use futures, here&amp;rsquo;s how we&amp;rsquo;d run this computation synchronously&amp;mdash;we
just call the function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;// Synchronous version
fn main() {
    if is_prime(BIG_PRIME) {
        println!(&amp;quot;Prime&amp;quot;);
    } else {
        println!(&amp;quot;Not prime&amp;quot;);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The effect is that the main thread is blocked until the computation finishes,
and then it prints out the result.&lt;/p&gt;

&lt;h5 id=&#34;asynchronous-version&#34;&gt;Asynchronous version&lt;/h5&gt;

&lt;p&gt;Now let&amp;rsquo;s use futures and a thread pool to launch the computation
asynchronously:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use futures::Future;
use futures_cpupool::CpuPool;

fn main() {
    // set up a thread pool
    let pool = CpuPool::new_num_cpus();

    // spawn our computation, getting back a *future* of the answer
    let prime_future = pool.spawn_fn(|| {
        let prime = is_prime(BIG_PRIME);

        // For reasons we&#39;ll see later, we need to return a Result here
        let res: Result&amp;lt;bool, ()&amp;gt; = Ok(prime);
        res
    });

    println!(&amp;quot;Created the future&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This version of the code pushes work onto a thread pool, and &lt;em&gt;immediately&lt;/em&gt;
returns a future, &lt;code&gt;prime_future&lt;/code&gt;. Thus, we&amp;rsquo;ll see &lt;code&gt;Created the future&lt;/code&gt; on the
console right away, while the primality test is done in the background. Of
course, this isn&amp;rsquo;t so useful&amp;mdash;we&amp;rsquo;ve thrown away the answer!&lt;/p&gt;

&lt;p&gt;Even though futures are asynchronous, you always have the option of treating
them synchronously, by &lt;em&gt;waiting&lt;/em&gt; for completion:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;// ...

println!(&amp;quot;Created the future&amp;quot;);

// unwrap here since we know the result is Ok
if prime_future.wait().unwrap() {
    println!(&amp;quot;Prime&amp;quot;);
} else {
    println!(&amp;quot;Not prime&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While
&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.wait&#34;&gt;&lt;code&gt;wait&lt;/code&gt;&lt;/a&gt;
isn&amp;rsquo;t very commonly used in practice, it&amp;rsquo;s a nice illustration of the difference
between a future (like &lt;code&gt;prime_future&lt;/code&gt;) and the value it produces; the future is
returned right away, allowing you to do additional work concurrently (like
printing a message, here), and retrieve the value later on.&lt;/p&gt;

&lt;h5 id=&#34;adding-a-timeout&#34;&gt;Adding a timeout&lt;/h5&gt;

&lt;p&gt;So far this example isn&amp;rsquo;t terribly interesting, since there are simpler ways to
work with thread pools. But one strength of futures is their ability to
&lt;em&gt;combine&lt;/em&gt;. We&amp;rsquo;ll show this off by combining the thread pool future with a
timeout future:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;use tokio_timer::Timer;
use futures::Future;
use std::time::Duration;
use futures_cpupool::CpuPool;

fn main() {
    let pool = CpuPool::new_num_cpus();
    let timer = Timer::default();

    // a future that resolves to Err after a timeout
    let timeout = timer.sleep(Duration::from_millis(750))
        .then(|_| Err(()));

    // a future that resolves to Ok with the primality result
    let prime = pool.spawn_fn(|| {
        Ok(is_prime(BIG_PRIME))
    });

    // a future that resolves to one of the above values -- whichever
    // completes first!
    let winner = timeout.select(prime).map(|(win, _)| win);

    // now block until we have a winner, than print what happened
    match winner.wait() {
        Ok(true) =&amp;gt; println!(&amp;quot;Prime&amp;quot;),
        Ok(false) =&amp;gt; println!(&amp;quot;Not prime&amp;quot;),
        Err(_) =&amp;gt; println!(&amp;quot;Timed out&amp;quot;),
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, we&amp;rsquo;re using a couple of additional methods on futures:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.then&#34;&gt;&lt;code&gt;then&lt;/code&gt;&lt;/a&gt;,
which in general allows you to sequence one future to run after getting the
value of another. In this case, we&amp;rsquo;re just using it to change the value
returned from the timeout future to &lt;code&gt;Err(())&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.select&#34;&gt;&lt;code&gt;select&lt;/code&gt;&lt;/a&gt;,
which combines two futures of the same type, allowing them to &amp;ldquo;race&amp;rdquo; to
completion. It yields a pair, where the first component is the value produced
by the first future to complete, and the second gives you the other future
back. Here, we just take the winning value.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While this example is simplistic, it gives some sense for how futures scale
up. Once you have a number of basic &amp;ldquo;events&amp;rdquo; set up as futures, you can combine
them in complex ways, and the futures library takes care of tracking all of the
relevant state and synchronization.&lt;/p&gt;

&lt;h5 id=&#34;whence-i-o&#34;&gt;Whence I/O?&lt;/h5&gt;

&lt;p&gt;We haven&amp;rsquo;t shown how to work directly with I/O events as futures. That&amp;rsquo;s because
I/O is a bit more complicated, and you often end up working with sibling
abstractions to futures: streams and sinks. These are all covered in subsequent
guides.&lt;/p&gt;

&lt;h2 id=&#34;the-future-trait&#34;&gt;The &lt;code&gt;Future&lt;/code&gt; trait&lt;/h2&gt;

&lt;p&gt;At this point, we&amp;rsquo;ve seen just a tiny bit of the futures API&amp;mdash;but what actually
&lt;em&gt;is&lt;/em&gt; a future?&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;futures-rs&lt;/code&gt; library, a future is anything that implements the
&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html&#34;&gt;&lt;code&gt;Future&lt;/code&gt; trait&lt;/a&gt;,
which has a lot of similarities to the
&lt;a href=&#34;https://static.rust-lang.org/doc/master/std/iter/trait.Iterator.html&#34;&gt;&lt;code&gt;Iterator&lt;/code&gt; trait&lt;/a&gt;
in the standard library:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;trait Future {
    // The type of value that the future yields on successful completion.
    type Item;

    // The type of value that the future yields on failure.
    type Error;

    // The only required method, which attempts to complete the future.
    fn poll(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;Self::Item, Self::Error&amp;gt;;

    // Blocks until completion.
    fn wait(self) -&amp;gt; Result&amp;lt;Self::Item, Self::Error&amp;gt; { ... }

    // Transforms the result of the future using the gives closure.
    fn map&amp;lt;F, U&amp;gt;(self, f: F) -&amp;gt; Map&amp;lt;Self, F&amp;gt;
        where F: FnOnce(Self::Item) -&amp;gt; U { ... }

    // ... and many, many more provided methods
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since futures are primarily motivated by I/O, error handling is an important
concern baked in to the trait and its methods.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;poll&lt;/code&gt; method is the heart of the futures trait&amp;mdash;it&amp;rsquo;s how futures actually
do their work. However, it&amp;rsquo;s not generally called directly. Instead, you tend to
work through the other methods of the &lt;code&gt;Future&lt;/code&gt; trait (which are all default methods).
You can find an in-depth explanation of &lt;code&gt;poll&lt;/code&gt; in TODO.&lt;/p&gt;

&lt;p&gt;So that&amp;rsquo;s the quick tour. In the next section, we&amp;rsquo;ll look at a more involved
example: hooking up a database to the &lt;a href=&#34;../simple-server&#34;&gt;line-based protocol&lt;/a&gt; we
developed earlier.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example: serving database content using proto</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/db/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/db/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Streams and sinks</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/streams-and-sinks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/streams-and-sinks/</guid>
      <description>

&lt;p&gt;We&amp;rsquo;ve now seen a few examples of futures, which represent a &lt;em&gt;one-time&lt;/em&gt;
asynchronous event. But there are a lot of cases where you want to deal with a
&lt;em&gt;series&lt;/em&gt; of events:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;incoming connections over time,&lt;/li&gt;
&lt;li&gt;incoming or outgoing network packets,&lt;/li&gt;
&lt;li&gt;incoming or outgoing chunks of a streaming protocol,&lt;/li&gt;
&lt;li&gt;repeated timeouts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and so on.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;futures-rs&lt;/code&gt; library provides two abstractions that are similar to futures,
but work with series of events over time: streams and sinks. Streams are for
incoming events (which are caused by something external happening, like a
timeout firing) while sinks are for outgoing events (like sending a message
chunk).&lt;/p&gt;

&lt;h2 id=&#34;streams&#34;&gt;Streams&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s see how &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/trait.Future.html&#34;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; relate to their synchronous equivalents
in the standard library:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;# items&lt;/th&gt;
&lt;th&gt;Sync&lt;/th&gt;
&lt;th&gt;Async&lt;/th&gt;
&lt;th&gt;Common operations&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doc.rust-lang.org/std/result/enum.Result.html&#34;&gt;&lt;code&gt;Result&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/trait.Future.html&#34;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/trait.Future.html#method.map&#34;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;âˆž&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://doc.rust-lang.org/std/iter/trait.Iterator.html&#34;&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.map&#34;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.fold&#34;&gt;&lt;code&gt;fold&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.collect&#34;&gt;&lt;code&gt;collect&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The definition of the &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; trait also resembles that of &lt;a href=&#34;https://doc.rust-lang.org/std/iter/trait.Iterator.html&#34;&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;trait Stream {
    // The type of item yielded each time the stream&#39;s event occurs
    type Item;

    // The error type; errors terminate the stream.
    type Error;

    // Try to produce a value.
    fn poll(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;Option&amp;lt;Self::Item&amp;gt;, Self::Error&amp;gt;;

    // ... and many default methods; we&#39;ll see some of them below.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; trait is very similar to the &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/trait.Future.html&#34;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt; trait, except that a
stream&amp;rsquo;s &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#tymethod.poll&#34;&gt;&lt;code&gt;poll&lt;/code&gt;&lt;/a&gt; method returns &lt;code&gt;Option&amp;lt;Self::Item&amp;gt;&lt;/code&gt; instead of
&lt;code&gt;Self::Item&lt;/code&gt;. The semantics are much like with &lt;a href=&#34;https://doc.rust-lang.org/std/iter/trait.Iterator.html&#34;&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;: yielding &lt;code&gt;None&lt;/code&gt;
means that the stream has terminated. Like futures, streams can produce
errors, which &lt;em&gt;also&lt;/em&gt; terminate the stream.&lt;/p&gt;

&lt;p&gt;The stream API is easiest to understand by example, so let&amp;rsquo;s write a little
server that immediately sends &amp;ldquo;Hello, world!&amp;rdquo; to each client that connects, and
then hangs up. (We&amp;rsquo;ll use &lt;code&gt;tokio-core&lt;/code&gt; in this example, which is covered in
greater depth in the next section.)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;extern crate futures;
extern crate tokio_core;

use futures::stream::Stream;
use tokio_core::reactor::Core;
use tokio_core::net::TcpListener;

fn main() {
    let mut core = Core::new().unwrap();
    let address = &amp;quot;0.0.0.0:12345&amp;quot;.parse().unwrap();
    let listener = TcpListener::bind(&amp;amp;address, &amp;amp;core.handle()).unwrap();

    let connections = listener.incoming();
    let welcomes = connections.and_then(|(socket, _peer_addr)| {
        tokio_core::io::write_all(socket, b&amp;quot;Hello, world!\n&amp;quot;)
    });
    let server = welcomes.for_each(|(_socket, _welcome)| {
        Ok(())
    });

    core.run(server).unwrap();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was easy! Let&amp;rsquo;s pick apart a few key lines. First, there&amp;rsquo;s the &lt;em&gt;reactor setup&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let mut core = Core::new().unwrap();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll cover reactors (aka &lt;em&gt;event loops&lt;/em&gt;) in detail in the next section. For now,
it&amp;rsquo;s enough to know that if you&amp;rsquo;re doing asynchronous I/O, it needs to be
managed by a reactor. The &lt;code&gt;tokio-proto&lt;/code&gt; crate takes care of this for you, but
here we&amp;rsquo;re working at a lower level.&lt;/p&gt;

&lt;p&gt;We then set up an async TCP listener, associated with that reactor:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let listener = TcpListener::bind(&amp;amp;address, &amp;amp;core.handle()).unwrap();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our first encounter with streams is the &lt;code&gt;incoming&lt;/code&gt; stream:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let connections = listener.incoming();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is an unending stream of sockets, one for each
incoming connection. It&amp;rsquo;s an async version of
&lt;a href=&#34;https://static.rust-lang.org/doc/master/std/net/struct.TcpListener.html#method.incoming&#34;&gt;the same method&lt;/a&gt;
in the standard library. And just as with iterators, we can use the methods on
the &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; trait to manipulate the stream:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let welcomes = connections.and_then(|(socket, _peer_addr)| {
    tokio_core::io::write_all(socket, b&amp;quot;Hello, world!\n&amp;quot;)
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we use &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; to perform an action over each item of
the stream, a bit like &lt;code&gt;and_then&lt;/code&gt; on &lt;code&gt;Result&lt;/code&gt;, except that the closure we give
&lt;code&gt;and_then&lt;/code&gt; produces a future. We get back a &lt;em&gt;new&lt;/em&gt; stream, &lt;code&gt;welcomes&lt;/code&gt;. Here&amp;rsquo;s how
&lt;code&gt;welcome&lt;/code&gt; produces its items:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First, get an item from &lt;code&gt;connections&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Then, map that item through the closure, getting back a future.&lt;/li&gt;
&lt;li&gt;When that future completes, return the item it produced as the next item of
the &lt;code&gt;welcomes&lt;/code&gt; stream.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The future we use is &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/io/fn.write_all.html&#34;&gt;&lt;code&gt;write_all&lt;/code&gt;&lt;/a&gt; from the &lt;code&gt;tokio-core&lt;/code&gt; crate. It
asynchronously entire buffer to the socket provided, then returns the socket and
ownership of that buffer. So &lt;code&gt;welcomes&lt;/code&gt; is again a stream that includes one
socket for each connection, with &lt;code&gt;Hello, world!&lt;/code&gt; written to them.  We&amp;rsquo;re done
with the connection at that point.&lt;/p&gt;

&lt;p&gt;How do we actually consume this stream? As with iterators, loops are a common
way to consume streams&amp;mdash;but we use the futures-based &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html#method.for_each&#34;&gt;&lt;code&gt;for_each&lt;/code&gt;&lt;/a&gt; method:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let server = welcomes.for_each(|(_socket, _welcome)| {
    Ok(())
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we take the results of the previous future, &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/io/fn.write_all.html&#34;&gt;&lt;code&gt;write_all&lt;/code&gt;&lt;/a&gt;, and discard
them, closing the socket. What we get back is a &lt;em&gt;single future&lt;/em&gt;, &lt;code&gt;server&lt;/code&gt;, which
completes with &lt;code&gt;()&lt;/code&gt; only when the entire stream has been exhausted (and hence,
we&amp;rsquo;ve replied to all connections). It&amp;rsquo;s a pretty common pattern, when working
with streams, to ultimately &amp;ldquo;bottom things out&amp;rdquo; into a single future that
represents fully processing the stream.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s one final step: we need to consume the &lt;code&gt;server&lt;/code&gt; future, which is
otherwise inert, to actually trigger all this processing. We also need to start
up the reactor. We do both in a single step, by using the server as the &lt;em&gt;primary
future&lt;/em&gt; of the reactor:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;core.run(server).unwrap();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The reactor&amp;rsquo;s event loop will keep running on the current thread until the
server future completes successfully or with an error.&lt;/p&gt;

&lt;h5 id=&#34;concurrency&#34;&gt;Concurrency&lt;/h5&gt;

&lt;p&gt;There&amp;rsquo;s an important point to drive home about the previous example: it has &lt;em&gt;no
concurrency&lt;/em&gt;!  Streams represent in-order processing of data, and in this case
the order of the original stream is the order in which sockets are received,
which the &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html#method.for_each&#34;&gt;&lt;code&gt;for_each&lt;/code&gt;&lt;/a&gt; combinators
preserve. Chaining these combinators therefore has the effect of taking each
socket from the stream and processing all chained operations on it before taking
the next socket.&lt;/p&gt;

&lt;p&gt;If, instead, we want to handle all clients concurrently, we can use the
reactor&amp;rsquo;s ability to &amp;ldquo;spawn&amp;rdquo; additional work:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let handle = core.handle();
let server = connections.for_each(|(socket, _peer_addr)| {
    let serve_one = tokio_core::io::write_all(socket, b&amp;quot;Hello, world!\n&amp;quot;)
            .then(|_| Ok(()));
    handle.spawn(serve_one);
    Ok(())
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/reactor/struct.Handle.html#method.spawn&#34;&gt;&lt;code&gt;spawn&lt;/code&gt;&lt;/a&gt; requires a future with &lt;code&gt;()&lt;/code&gt; item and error types, since the
result of the future is not accessible. We use &lt;code&gt;then&lt;/code&gt; to explicitly throw away
the socket returned from &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/io/fn.write_all.html&#34;&gt;&lt;code&gt;write_all&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Unlike with &lt;code&gt;CpuPool&lt;/code&gt;, the reactor is always an event loop that runs on a
&lt;em&gt;single&lt;/em&gt; thread (the one that calls &lt;code&gt;run&lt;/code&gt;). When we use &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/reactor/struct.Handle.html#method.spawn&#34;&gt;&lt;code&gt;spawn&lt;/code&gt;&lt;/a&gt; to add work to
the reactor, we are effectively creating a &lt;em&gt;lightweight thread&lt;/em&gt;: we move the
future itself onto the reactor, and as relevant events arrive, the reactor will
attempt to run the future to completion. It&amp;rsquo;s important to be clear on the
mechanics here, so let&amp;rsquo;s work through an example.&lt;/p&gt;

&lt;p&gt;After calling &lt;code&gt;core.run&lt;/code&gt;, the event loop blocks until a connection
arrives. Suppose two connections arrive at the same time.  At that point, the
event loop will emit two sockets on the &lt;code&gt;connections&lt;/code&gt; stream, which will result
in two spawned &lt;code&gt;Hello, world!&lt;/code&gt; futures. The event loop will then attempt to
complete those futures, one at a time.  Each futures will attempt to write to
its socket. If its socket is not ready to receive data, the future will go into
a &lt;em&gt;waiting state&lt;/em&gt; until the status of the socket changes; the event loop &lt;em&gt;does
not&lt;/em&gt; block. Once the socket &lt;em&gt;is&lt;/em&gt; ready, the event loop will again start trying
to make progress on the future.&lt;/p&gt;

&lt;p&gt;So we end up multiplexing all connection handling onto a single event loop
thread. That thread will make progress on all outstanding futures with I/O ready
to be performed, and will not be blocked by any future that has stalled waiting
for a socket. For a server as simple as this one, handling concurrency by
multiplexing onto a single thread is a performance big win compared to
coordinating multiple threads. In other cases, we might use a &lt;code&gt;CpuPool&lt;/code&gt; for
CPU-heavy work, and use the event loop primarily for I/O-heavy work, to try to
maximize locality and parallelism.&lt;/p&gt;

&lt;p&gt;All of the multiplexing and dispatch is handled behind the scenes by the reactor
and futures; we just write code that looks pretty close to synchronous code that
spawns a thread per connection.&lt;/p&gt;

&lt;h2 id=&#34;sinks&#34;&gt;Sinks&lt;/h2&gt;

&lt;p&gt;Sinks are essentially the opposite of streams: they are places that you can
asynchronously send many values over time. As usual, sinks are types that
implement the &lt;code&gt;Sink&lt;/code&gt; trait:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;trait Sink {
    // The type of value that the sink accepts.
    type SinkItem;

    // The type of value produced by the sink when an error occurs.
    type SinkError;

    // The analog to `poll`, used for sending and then flushing items.
    fn start_send(&amp;amp;mut self, item: Self::SinkItem)
                  -&amp;gt; StartSend&amp;lt;Self::SinkItem, Self::SinkError&amp;gt;;
    fn poll_complete(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;(), Self::SinkError&amp;gt;;

    // ... and lots of default methods, as usual
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We&amp;rsquo;ll see some example uses of sinks in the next section, so for now we&amp;rsquo;ll just
mention two of the most important methods it offers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/sink/trait.Sink.html#method.send_all&#34;&gt;&lt;code&gt;send_all&lt;/code&gt;&lt;/a&gt; method takes a stream with &lt;code&gt;Item&lt;/code&gt; the same as &lt;code&gt;SinkItem&lt;/code&gt;, and
gives you back a future that produces &lt;code&gt;()&lt;/code&gt;. As the name suggests, this future,
when executed, will asynchronously send all items from the stream into the
sink, completing when the stream has been exhausted and all items have been
&lt;em&gt;flushed&lt;/em&gt; through the sink.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/sink/trait.Sink.html#method.buffer&#34;&gt;&lt;code&gt;buffer&lt;/code&gt;&lt;/a&gt; method wraps a sink with a fixed-size buffer, allowing it to
accept additional items even when the underlying sink is not ready for
items. That&amp;rsquo;s useful for buffering up responses on a socket, for example.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most of the time, the interesting work happens on the stream and future sides,
with sinks acting as a final endpoint for pushing data through.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Understanding event loops</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/reactor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/reactor/</guid>
      <description>

&lt;p&gt;Now we&amp;rsquo;ll take a bit more of a dive into &lt;code&gt;tokio-core&lt;/code&gt;. Keep in mind that this
layer of the stack is intended mainly for lower-level async programming;
&lt;code&gt;tokio-proto&lt;/code&gt; is generally nicer to work with when it meets your needs. Still,
it can be helpful to understand how &lt;code&gt;tokio-core&lt;/code&gt; works whether or not you use it
directly.&lt;/p&gt;

&lt;p&gt;Almost all asynchronous libraries are powered in one form or another by an
&lt;strong&gt;event loop&lt;/strong&gt;. That&amp;rsquo;s just a fancy term for code like this executing
on a thread:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;loop {
    // Learn what the next &amp;quot;event&amp;quot; was, blocking if none available
    let event = next_event();

    // Dispatch this event, following it through to completion
    dispatch(event);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So an event loop is literally a &lt;code&gt;loop&lt;/code&gt; that blocks, waiting for the next &amp;ldquo;event&amp;rdquo;
in an asynchronous system, and then acts on the event appropriately. Events
cover a wide spectrum:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A socket is now readable&lt;/li&gt;
&lt;li&gt;An I/O write has finished&lt;/li&gt;
&lt;li&gt;External work for a future has completed, and it can make progress&lt;/li&gt;
&lt;li&gt;A timeout fired&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &amp;ldquo;dispatch&amp;rdquo; above is also very general; it just means &amp;ldquo;taking appropriate
action&amp;rdquo; to respond to an event, for example, by scheduling a write after a read
is finished, attempting to complete a future&amp;rsquo;s state machine, or starting
handling timeout logic for a timeout which fired.&lt;/p&gt;

&lt;h2 id=&#34;the-event-loop-of-tokio-core&#34;&gt;The event loop of &lt;code&gt;tokio-core&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The heart of the &lt;code&gt;tokio-core&lt;/code&gt; library is the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/index.html&#34;&gt;&lt;code&gt;tokio_core::reactor&lt;/code&gt;&lt;/a&gt; module;
&amp;ldquo;reactor&amp;rdquo; is a common synonym for &amp;ldquo;event loop&amp;rdquo;. The module contains the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt;
type, which is the actual event loop, as well as the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/a&gt;
types, which are used to send messages and interact with the event loop without
holding the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt; itself.&lt;/p&gt;

&lt;h3 id=&#34;core&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt; type has a relatively small API surface area; the main item of
interest is the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html#method.run&#34;&gt;&lt;code&gt;run&lt;/code&gt;&lt;/a&gt; method. This method takes a future, &lt;code&gt;F&lt;/code&gt;,
and starts executing an event loop on the current thread until the future &lt;code&gt;F&lt;/code&gt; is
completed. While this may look similar to &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.wait&#34;&gt;&lt;code&gt;Future::wait&lt;/code&gt;&lt;/a&gt;, there&amp;rsquo;s a crucial
difference: while its waiting for the future to resolve it executes other work
on the event loop rather than just blocking the thread. As we saw in the
&lt;a href=&#34;../streams-and-sinks&#34;&gt;previous section&lt;/a&gt;, that other work includes tasks that
were spawned onto the event loop.&lt;/p&gt;

&lt;p&gt;Most servers consist of some setup, followed by running the event loop with a
connection-handling future, as we also saw before. To recap, the basic structure
looks as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;extern crate futures;
extern crate tokio_core;

use futures::Stream;
use tokio_core::net::TcpListener;
use tokio_core::reactor::Core;

fn main() {
    let mut core = Core::new().unwrap();
    let listener = TcpListener::bind(&amp;amp;&amp;quot;127.0.0.1:8080&amp;quot;.parse().unwrap(),
                                     &amp;amp;core.handle()).unwrap();

    let server = listener.incoming().for_each(|(client, client_addr)| {
        // process `client` by spawning a new task ...

        Ok(()) // keep accepting connections
    });

    core.run(server).unwrap();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For clients, however, you can use the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html#method.run&#34;&gt;&lt;code&gt;run&lt;/code&gt;&lt;/a&gt; method for one-off
futures or otherwise one-off tasks. Some pseudo-code for this could look like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let my_request = http::get(&amp;quot;https://www.rust-lang.org&amp;quot;);
let my_response = my_context.core.run(my_request).unwrap();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt; could be stashed in a local context which is used whenever
executing a future, but is otherwise idle while the client is processing other
tasks. Alternatively a thread could be spawned on a client running a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt;
and work could be shipped over to it whenever necessary and returned later;
we&amp;rsquo;ll see how to do that with &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/a&gt; in just a moment.&lt;/p&gt;

&lt;h3 id=&#34;handle&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;In general, the code being run by the event loop needs the ability to make
additional requests of the event loop, and thus needs some way to access the
loop. Consequently, the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt; type provides the ability to acquire an owned
&lt;em&gt;handle&lt;/em&gt; to itself through the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt; type created through the
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html#method.handle&#34;&gt;&lt;code&gt;Core::handle&lt;/code&gt;&lt;/a&gt; method.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s first take a look at the &lt;code&gt;Handle&lt;/code&gt;&amp;rsquo;s &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html#method.spawn&#34;&gt;&lt;code&gt;spawn&lt;/code&gt;&lt;/a&gt; method. Like
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html#method.run&#34;&gt;&lt;code&gt;Core::run&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html#method.spawn&#34;&gt;&lt;code&gt;spawn&lt;/code&gt;&lt;/a&gt; will ensure the provided future run to
completion. Unlike &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html#method.run&#34;&gt;&lt;code&gt;Core::run&lt;/code&gt;&lt;/a&gt;, however, spawning requires the item/error type
of a future to be &lt;code&gt;()&lt;/code&gt; and also requires the &lt;code&gt;&#39;static&lt;/code&gt; bound. The requirement of
&lt;code&gt;()&lt;/code&gt; signifies that future is executed in the background of the event loop to
completion and must have its own error handling.&lt;/p&gt;

&lt;p&gt;As we saw in the last section, the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html#method.spawn&#34;&gt;&lt;code&gt;spawn&lt;/code&gt;&lt;/a&gt; method is useful
for spawning off work dynamically onto an event loop. All spawned work &lt;em&gt;is
executed concurrently&lt;/em&gt; on the event loop thread, which is typically ideal, for
example, when handling TCP connections. Taking our &lt;code&gt;run&lt;/code&gt; example from before, we
could enhance it by handling all clients concurrently by adding:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;// Acquire a `Handle` and then use that to spawn work for each client as
// they&#39;re accepted from the TCP socket.
let handle = core.handle();
let server = listener.incoming().for_each(|(client, _client_addr)| {
    handle.spawn(process(client));

    Ok(()) // keep accepting connections
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and add a &lt;code&gt;process&lt;/code&gt; function for handling a client:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;// Here we&#39;ll express the handling of `client` and return it as a future
// to be spawned onto the event loop.
fn process(client: TcpStream) -&amp;gt; Box&amp;lt;Future&amp;lt;Item = (), Error = ()&amp;gt;&amp;gt; {
    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Beyond spawning threads, a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt; is also use for constructing objects
associated with the event loop. For example the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.TcpListener.html#method.bind&#34;&gt;&lt;code&gt;TcpListener::bind&lt;/code&gt;&lt;/a&gt; method
that we&amp;rsquo;ve been using takes &lt;code&gt;&amp;amp;Handle&lt;/code&gt; as its second argument.&lt;/p&gt;

&lt;h3 id=&#34;remote&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;With &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt; we&amp;rsquo;re now able to retain a reference to the event loop without
holding a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt; itself. The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt; type itself, however, is not sendable
across threads; it is only usable on the event loop thread itself, which gives
substantial performance benefits. If you need to communicate with the event loop
from a different thread, you can use the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/a&gt; type as a form of
&amp;ldquo;downgraded&amp;rdquo; handle. You can get a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/a&gt; by calling the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;remote&lt;/code&gt;&lt;/a&gt; method
on a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/a&gt;, like &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt; is associated with an event loop (e.g. it&amp;rsquo;s
another kind of handle to &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt;). &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/a&gt;, however, can be sent across
threads. The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html&#34;&gt;&lt;code&gt;Remote&lt;/code&gt;&lt;/a&gt; type also currently only has a
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html#method.spawn&#34;&gt;&lt;code&gt;spawn&lt;/code&gt;&lt;/a&gt; function. This &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html#method.spawn&#34;&gt;&lt;code&gt;spawn&lt;/code&gt;&lt;/a&gt; is
importantly different from &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html#method.spawn&#34;&gt;&lt;code&gt;Handle::spawn&lt;/code&gt;&lt;/a&gt; in that it takes a &lt;em&gt;closure&lt;/em&gt; which
is &lt;code&gt;Send&lt;/code&gt; (can be sent across threads) which crates a future. The created future
is then spawned onto the event loop to be executed locally.&lt;/p&gt;

&lt;p&gt;The closure provided, when run, is yielded a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html&#34;&gt;&lt;code&gt;Handle&lt;/code&gt;&lt;/a&gt; as proof that it&amp;rsquo;s
running on the same thread as the event loop. This handle can then be used to
create and work with I/O objects. Like &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Handle.html#method.spawn&#34;&gt;&lt;code&gt;Handle::spawn&lt;/code&gt;&lt;/a&gt; the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Remote.html#method.spawn&#34;&gt;&lt;code&gt;Remote::spawn&lt;/code&gt;&lt;/a&gt;
method requires the item/error types of the future to be &lt;code&gt;()&lt;/code&gt; as it&amp;rsquo;s run
concurrently.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>High-level I/O using core</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/core/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/core/</guid>
      <description>

&lt;p&gt;At this point we&amp;rsquo;ve got a pretty solid grasp on what event loops are and how
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/reactor/struct.Core.html&#34;&gt;&lt;code&gt;Core&lt;/code&gt;&lt;/a&gt; allows us to work with futures on an event loop. Let&amp;rsquo;s get down to
business and do some I/O! In this section, we&amp;rsquo;ll cover &amp;ldquo;high-level&amp;rdquo; I/O with
&lt;code&gt;tokio-core&lt;/code&gt;, where we&amp;rsquo;ll work with futures, streams and sinks. A
&lt;a href=&#34;../../going-deeper/core-low-level&#34;&gt;later section&lt;/a&gt; will explain how to work at
the lowest level with &lt;code&gt;tokio-core&lt;/code&gt;, which gives you maximal control over things
like buffering strategy.&lt;/p&gt;

&lt;h3 id=&#34;concrete-i-o-types&#34;&gt;Concrete I/O types&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/tokio-core/0.1&#34;&gt;&lt;code&gt;tokio-core&lt;/code&gt;&lt;/a&gt; crate doesn&amp;rsquo;t provide a full suite of I/O primitives; it&amp;rsquo;s
focused on TCP/UDP networking types. That&amp;rsquo;s because these are the only I/O
objects that you can work with asynchronously across Rust&amp;rsquo;s main platforms.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/&#34;&gt;&lt;code&gt;tokio_core::net&lt;/code&gt;&lt;/a&gt; module you&amp;rsquo;ll find types like
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.TcpListener.html&#34;&gt;&lt;code&gt;TcpListener&lt;/code&gt;&lt;/a&gt; we&amp;rsquo;ve been using in examples prior, &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.TcpStream.html&#34;&gt;&lt;code&gt;TcpStream&lt;/code&gt;&lt;/a&gt;, and
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.UdpSocket.html&#34;&gt;&lt;code&gt;UdpSocket&lt;/code&gt;&lt;/a&gt;. These networking types serve as the core foundation for most
servers and should look very similar to their &lt;a href=&#34;https://doc.rust-lang.org/std/net/&#34;&gt;standard library
counterparts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The main difference between &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/&#34;&gt;&lt;code&gt;tokio_core::net&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://doc.rust-lang.org/std/net/&#34;&gt;&lt;code&gt;std::net&lt;/code&gt;&lt;/a&gt; is that the
Tokio versions are all &lt;em&gt;non-blocking&lt;/em&gt;. The &lt;code&gt;Read&lt;/code&gt;/&lt;code&gt;Write&lt;/code&gt; trait implementations
are not blocking and will return a &amp;ldquo;would block&amp;rdquo; error instead of blocking (see
the &lt;a href=&#34;../../going-deeper/core-low-level&#34;&gt;low-level I/O section&lt;/a&gt; for more).
Similarly types are also enhanced with futures-aware methods such as
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.TcpStream.html#method.connect&#34;&gt;&lt;code&gt;TcpStream::connect&lt;/code&gt;&lt;/a&gt; returning a future or &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.Incoming.html&#34;&gt;&lt;code&gt;TcpListener::incoming&lt;/code&gt;&lt;/a&gt; returning
a stream.&lt;/p&gt;

&lt;h3 id=&#34;i-o-helpers&#34;&gt;I/O helpers&lt;/h3&gt;

&lt;p&gt;In addition to the concrete networking types &lt;a href=&#34;https://docs.rs/tokio-core/0.1&#34;&gt;&lt;code&gt;tokio-core&lt;/code&gt;&lt;/a&gt; also provides a
number of utilities in the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/&#34;&gt;&lt;code&gt;tokio_core::io&lt;/code&gt;&lt;/a&gt; module for working with I/O
objects When using these utilities, it&amp;rsquo;s important to remember a few points:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;They only work with &amp;ldquo;futures aware&amp;rdquo; and nonblocking
implementations of &lt;code&gt;Read&lt;/code&gt;/&lt;code&gt;Write&lt;/code&gt;, though this should be the default if Tokio
types are used internally.&lt;/li&gt;
&lt;li&gt;They are intended to be &lt;em&gt;helpers&lt;/em&gt;. For your particular use case they may not
always be the most efficient. The helpers are intended to help you hit the
ground running and can easily be replaced with application-specific logic in
the future if necessary.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/&#34;&gt;&lt;code&gt;tokio_core::io&lt;/code&gt;&lt;/a&gt; module provides a suite of helper functions to express
I/O operations as futures, such as &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/fn.read_to_end.html&#34;&gt;&lt;code&gt;read_to_end&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/fn.write_all.html&#34;&gt;&lt;code&gt;write_all&lt;/code&gt;&lt;/a&gt;. The
functions take the I/O object, and any relevant buffers, by value. The resulting
futures then yield back ownership of these values, so you can continue using
them.  Threading ownership in this way is necessary in part because futures are
often required to be &lt;code&gt;&#39;static&lt;/code&gt;, making borrowing impossible.&lt;/p&gt;

&lt;p&gt;In addition to these functions, the module includes an &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html&#34;&gt;&lt;code&gt;Io&lt;/code&gt;&lt;/a&gt; trait. This trait
expresses the concept of an I/O object which implements both &lt;a href=&#34;https://doc.rust-lang.org/std/io/trait.Read.html&#34;&gt;&lt;code&gt;Read&lt;/code&gt;&lt;/a&gt; and
&lt;code&gt;Write&lt;/code&gt;. &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html&#34;&gt;&lt;code&gt;Io&lt;/code&gt;&lt;/a&gt; currently doesn&amp;rsquo;t have any required methods, but two methods
with default implementations are of particular note.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.split&#34;&gt;&lt;code&gt;Io::split&lt;/code&gt;&lt;/a&gt; method assists in working with &amp;ldquo;halves&amp;rdquo; of a stream
independently. This method essentially takes a &lt;code&gt;Read + Write&lt;/code&gt; objects and
returns two objects that implement &lt;a href=&#34;https://doc.rust-lang.org/std/io/trait.Read.html&#34;&gt;&lt;code&gt;Read&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;Write&lt;/code&gt;, respectively. This can
often be convenient when working with futures to ensure ownership is
managed correctly.&lt;/p&gt;

&lt;p&gt;The second method, &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.framed&#34;&gt;&lt;code&gt;Io::framed&lt;/code&gt;&lt;/a&gt;, is important enough that we&amp;rsquo;ll give it a
whole section!&lt;/p&gt;

&lt;h3 id=&#34;i-o-codecs-and-framing&#34;&gt;I/O codecs and framing&lt;/h3&gt;

&lt;p&gt;Working with a raw stream of bytes isn&amp;rsquo;t always the easiest thing to do,
especially in an asynchronous context. Additionally, many protocols aren&amp;rsquo;t
really byte-oriented but rather have a higher level &amp;ldquo;framing&amp;rdquo; they&amp;rsquo;re using.
Often this means that abstractions like &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.rs/futures/0.1/futures/sink/trait.Sink.html&#34;&gt;&lt;code&gt;Sink&lt;/code&gt;&lt;/a&gt; from the
&lt;a href=&#34;https://docs.rs/futures/0.1&#34;&gt;&lt;code&gt;futures&lt;/code&gt;&lt;/a&gt; crate are a perfect fit for a protocol, and you just need to somehow
get a stream of bytes into a &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; and &lt;code&gt;Sink&lt;/code&gt;. Thankfully, &lt;a href=&#34;https://docs.rs/tokio-core/0.1&#34;&gt;&lt;code&gt;tokio-core&lt;/code&gt;&lt;/a&gt;
helps you do exactly this with the last method of the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html&#34;&gt;&lt;code&gt;Io&lt;/code&gt;&lt;/a&gt; trait,
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.framed&#34;&gt;&lt;code&gt;Io::framed&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.framed&#34;&gt;&lt;code&gt;Io::framed&lt;/code&gt;&lt;/a&gt; method takes a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Codec.html&#34;&gt;&lt;code&gt;Codec&lt;/code&gt;&lt;/a&gt; which defines how to take a stream
and sink of bytes to a literal &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.rs/futures/0.1/futures/sink/trait.Sink.html&#34;&gt;&lt;code&gt;Sink&lt;/code&gt;&lt;/a&gt; implementation. This
method will return a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/struct.Framed.html&#34;&gt;&lt;code&gt;Framed&lt;/code&gt;&lt;/a&gt; which implements the &lt;a href=&#34;https://docs.rs/futures/0.1/futures/sink/trait.Sink.html&#34;&gt;&lt;code&gt;Sink&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt;
traits, using the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Codec.html&#34;&gt;&lt;code&gt;Codec&lt;/code&gt;&lt;/a&gt; provided to decode and encode frames. Note that a
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/struct.Framed.html&#34;&gt;&lt;code&gt;Framed&lt;/code&gt;&lt;/a&gt; can be split with &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html#method.split&#34;&gt;&lt;code&gt;Stream::split&lt;/code&gt;&lt;/a&gt; into two halves (like
&lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.split&#34;&gt;&lt;code&gt;Io::split&lt;/code&gt;&lt;/a&gt;) if necessary.&lt;/p&gt;

&lt;p&gt;As we saw &lt;a href=&#34;../simple-server&#34;&gt;much earlier&lt;/a&gt;, a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Codec.html&#34;&gt;&lt;code&gt;Codec&lt;/code&gt;&lt;/a&gt; defines how to decode
data received on the I/O stream, as well as how to encode frames back into the
I/O stream. This sort of operation requires some level of buffering which is
typically quite a tricky topic in asynchronous I/O handling. The &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Codec.html&#34;&gt;&lt;code&gt;Codec&lt;/code&gt;&lt;/a&gt; trait
provides an &lt;a href=&#34;https://docs.rs/tokio-core/0.1.1/tokio_core/io/struct.EasyBuf.html&#34;&gt;&lt;code&gt;EasyBuf&lt;/code&gt;&lt;/a&gt; for decoding which is essentially a reference-counted
owned list of bytes. This allows efficient extraction of slices of the buffer
through &lt;a href=&#34;https://docs.rs/tokio-core/0.1.1/tokio_core/io/struct.EasyBuf.html#method.drain_to&#34;&gt;&lt;code&gt;EasyBuf::drain_to&lt;/code&gt;&lt;/a&gt;. For encoding a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Codec.html&#34;&gt;&lt;code&gt;Codec&lt;/code&gt;&lt;/a&gt; simply append bytes to
the provided &lt;code&gt;Vec&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As with other helpers in &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/&#34;&gt;&lt;code&gt;tokio_core::io&lt;/code&gt;&lt;/a&gt; the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Codec.html&#34;&gt;&lt;code&gt;Codec&lt;/code&gt;&lt;/a&gt; trait may not
perfectly suit your application, particularly with respect to buffering
strategies. Fear not, though, as the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.framed&#34;&gt;&lt;code&gt;Io::framed&lt;/code&gt;&lt;/a&gt; method is just meant to get
you up and running quickly. Crates like &lt;a href=&#34;https://github.com/tokio-rs/tokio-proto&#34;&gt;&lt;code&gt;tokio-proto&lt;/code&gt;&lt;/a&gt; work with a &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt;
and a &lt;a href=&#34;https://docs.rs/futures/0.1/futures/sink/trait.Sink.html&#34;&gt;&lt;code&gt;Sink&lt;/code&gt;&lt;/a&gt; directly, so you can swap out &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.framed&#34;&gt;&lt;code&gt;Io::framed&lt;/code&gt;&lt;/a&gt; with your own
implementation if it becomes a bottleneck.&lt;/p&gt;

&lt;h3 id=&#34;datagrams&#34;&gt;Datagrams&lt;/h3&gt;

&lt;p&gt;Note that most of this discussion has been around I/O or byte &lt;em&gt;streams&lt;/em&gt;, which
UDP importantly is not! To accommodate this, however, the &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.UdpSocket.html&#34;&gt;&lt;code&gt;UdpSocket&lt;/code&gt;&lt;/a&gt; type
also provides a number of methods for working with it conveniently:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/tokio-core/0.1.1/tokio_core/net/struct.UdpSocket.html#method.send_dgram&#34;&gt;&lt;code&gt;send_dgram&lt;/code&gt;&lt;/a&gt; allows you to express sending a datagram as a future, returning
an error if the entire datagram couldn&amp;rsquo;t be sent at once.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/tokio-core/0.1.1/tokio_core/net/struct.UdpSocket.html#method.recv_dgram&#34;&gt;&lt;code&gt;recv_dgram&lt;/code&gt;&lt;/a&gt; expresses reading a datagram into a buffer, yielding both the
buffer and the address it came from.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/tokio-core/0.1.1/tokio_core/net/struct.UdpSocket.html#method.framed&#34;&gt;&lt;code&gt;framed&lt;/code&gt;&lt;/a&gt; acts similarly to &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Io.html#method.framed&#34;&gt;&lt;code&gt;Io::framed&lt;/code&gt;&lt;/a&gt; in easing
transformation of a &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/net/struct.UdpSocket.html&#34;&gt;&lt;code&gt;UdpSocket&lt;/code&gt;&lt;/a&gt; to a &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/trait.Stream.html&#34;&gt;&lt;code&gt;Stream&lt;/code&gt;&lt;/a&gt; and a &lt;a href=&#34;https://docs.rs/futures/0.1/futures/sink/trait.Sink.html&#34;&gt;&lt;code&gt;Sink&lt;/code&gt;&lt;/a&gt;. Note that
this method takes a &lt;a href=&#34;https://docs.rs/tokio-core/0.1.1/tokio_core/net/trait.UdpCodec.html&#34;&gt;&lt;code&gt;UdpCodec&lt;/code&gt;&lt;/a&gt; which differs from &lt;a href=&#34;https://docs.rs/tokio-core/0.1/tokio_core/io/trait.Codec.html&#34;&gt;&lt;code&gt;Codec&lt;/code&gt;&lt;/a&gt; to better suit
datagrams as opposed to a byte stream.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Example: a simple pipelined server using core</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/pipeline-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/pipeline-server/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example: a toy HTTP&#43;TLS client using core</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/tls/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/tls/</guid>
      <description>&lt;p&gt;TODO: update this, make it fit in with the rest of the flow&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;extern crate futures;
extern crate tokio_core;
extern crate tokio_tls;

use std::net::ToSocketAddrs;

use futures::Future;
use tokio_core::reactor::Core;
use tokio_core::net::TcpStream;
use tokio_tls::ClientContext;

fn main() {
    let mut core = Core::new().unwrap();
    let addr = &amp;quot;www.rust-lang.org:443&amp;quot;.to_socket_addrs().unwrap().next().unwrap();

    let socket = TcpStream::connect(&amp;amp;addr, &amp;amp;core.handle());

    let tls_handshake = socket.and_then(|socket| {
        let cx = ClientContext::new().unwrap();
        cx.handshake(&amp;quot;www.rust-lang.org&amp;quot;, socket)
    });
    let request = tls_handshake.and_then(|socket| {
        tokio_core::io::write_all(socket, &amp;quot;\
            GET / HTTP/1.0\r\n\
            Host: www.rust-lang.org\r\n\
            \r\n\
        &amp;quot;.as_bytes())
    });
    let response = request.and_then(|(socket, _)| {
        tokio_core::io::read_to_end(socket, Vec::new())
    });

    let (_, data) = core.run(response).unwrap();
    println!(&amp;quot;{}&amp;quot;, String::from_utf8_lossy(&amp;amp;data));
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you place that file in &lt;code&gt;src/main.rs&lt;/code&gt;, and then execute &lt;code&gt;cargo run&lt;/code&gt;, you
should see the HTML of the Rust home page!&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a lot to digest here, though, so let&amp;rsquo;s walk through it
line-by-line. First up in &lt;code&gt;main()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let mut core = Core::new().unwrap();
let addr = &amp;quot;www.rust-lang.org:443&amp;quot;.to_socket_addrs().unwrap().next().unwrap();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/reactor/struct.Core.html#method.new&#34;&gt;create an event loop&lt;/a&gt; on which we will perform all our
I/O. Then we resolve the &amp;ldquo;www.rust-lang.org&amp;rdquo; host name by using
the standard library&amp;rsquo;s &lt;a href=&#34;https://doc.rust-lang.org/std/net/trait.ToSocketAddrs.html&#34;&gt;&lt;code&gt;to_socket_addrs&lt;/code&gt;&lt;/a&gt; method.&lt;/p&gt;

&lt;p&gt;Next up:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let socket = TcpStream::connect(&amp;amp;addr, &amp;amp;core.handle());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/reactor/struct.Core.html#method.handle&#34;&gt;get a handle&lt;/a&gt; to our event loop and connect to the host with
&lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html#method.connect&#34;&gt;&lt;code&gt;TcpStream::connect&lt;/code&gt;&lt;/a&gt;. Note, though, that &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html#method.connect&#34;&gt;&lt;code&gt;TcpStream::connect&lt;/code&gt;&lt;/a&gt; returns a
future! This means that we don&amp;rsquo;t actually have the socket yet, but rather it
will be fully connected at some later point in time.&lt;/p&gt;

&lt;p&gt;Once our socket is available we need to perform three tasks to download the
rust-lang.org home page:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Perform a TLS handshake. The home page is only served over HTTPS, so we had
to connect to port 443 and we&amp;rsquo;ll have to obey the TLS protocol.&lt;/li&gt;
&lt;li&gt;An HTTP &amp;lsquo;GET&amp;rsquo; request needs to be issued. For the purposes of this tutorial
we will write the request by hand, though in a serious program you would
use an HTTP client built on futures.&lt;/li&gt;
&lt;li&gt;Finally, we download the response by reading off all the data on the socket.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at each of these steps in detail, the first being:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let tls_handshake = socket.and_then(|socket| {
    let cx = ClientContext::new().unwrap();
    cx.handshake(&amp;quot;www.rust-lang.org&amp;quot;, socket)
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we use the &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; method on the [&lt;code&gt;Future&lt;/code&gt;] trait to continue
building on the future returned by &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html#method.connect&#34;&gt;&lt;code&gt;TcpStream::connect&lt;/code&gt;&lt;/a&gt;. The &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; method
takes a closure which receives the resolved value of this previous future. In
this case &lt;code&gt;socket&lt;/code&gt; will have type &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html&#34;&gt;&lt;code&gt;TcpStream&lt;/code&gt;&lt;/a&gt;. The &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; closure,
however, will not run if &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html#method.connect&#34;&gt;&lt;code&gt;TcpStream::connect&lt;/code&gt;&lt;/a&gt; returned an error.&lt;/p&gt;

&lt;p&gt;Once we have our &lt;code&gt;socket&lt;/code&gt;, we create a client TLS context via
&lt;a href=&#34;https://tokio-rs.github.io/tokio-tls/tokio_tls/struct.ClientContext.html#method.new&#34;&gt;&lt;code&gt;ClientContext::new&lt;/code&gt;&lt;/a&gt;. This type from the [&lt;code&gt;tokio-tls&lt;/code&gt;] crate
represents the client half of a TLS connection. Next we call the
&lt;a href=&#34;https://tokio-rs.github.io/tokio-tls/tokio_tls/struct.ClientContext.html#method.handshake&#34;&gt;&lt;code&gt;handshake&lt;/code&gt;&lt;/a&gt; method to actually perform the TLS handshake. The first
argument is the domain name we&amp;rsquo;re connecting to, with the I/O object
as the second.&lt;/p&gt;

&lt;p&gt;Like with &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html#method.connect&#34;&gt;&lt;code&gt;TcpStream::connect&lt;/code&gt;&lt;/a&gt; from before, the &lt;a href=&#34;https://tokio-rs.github.io/tokio-tls/tokio_tls/struct.ClientContext.html#method.handshake&#34;&gt;&lt;code&gt;handshake&lt;/code&gt;&lt;/a&gt; method
returns a future. The actual TLS handshake may take some time as the
client and server need to perform some I/O, agree on certificates,
etc. Once resolved, however, the future will become a &lt;a href=&#34;https://tokio-rs.github.io/tokio-tls/tokio_tls/struct.TlsStream.html&#34;&gt;&lt;code&gt;TlsStream&lt;/code&gt;&lt;/a&gt;,
similar to our previous &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html&#34;&gt;&lt;code&gt;TcpStream&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; combinator is doing some heavy lifting behind the
scenes here by ensuring that it executes futures in the right order
and keeping track of the futures in flight. Even better, the value
returned from &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; itself implements [&lt;code&gt;Future&lt;/code&gt;], so we can
keep chaining computation!&lt;/p&gt;

&lt;p&gt;Next up, we issue our HTTP request:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let request = tls_handshake.and_then(|socket| {
    tokio_core::io::write_all(socket, &amp;quot;\
        GET / HTTP/1.0\r\n\
        Host: www.rust-lang.org\r\n\
        \r\n\
    &amp;quot;.as_bytes())
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we take the future from the previous step, &lt;code&gt;tls_handshake&lt;/code&gt;, and
use &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt; again to continue the computation. The &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/io/fn.write_all.html&#34;&gt;&lt;code&gt;write_all&lt;/code&gt;&lt;/a&gt;
combinator writes the entirety of our HTTP request, issueing multiple
writes as necessary. Here we&amp;rsquo;re just doing a simple HTTP/1.0 request,
so there&amp;rsquo;s not much we need to write.&lt;/p&gt;

&lt;p&gt;The future returned by &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/io/fn.write_all.html&#34;&gt;&lt;code&gt;write_all&lt;/code&gt;&lt;/a&gt; will complete once all the data
has been written to the socket. Note that behind the scenes the
&lt;a href=&#34;https://tokio-rs.github.io/tokio-tls/tokio_tls/struct.TlsStream.html&#34;&gt;&lt;code&gt;TlsStream&lt;/code&gt;&lt;/a&gt; will actually be encrypting all the data we write before
sending it to the underlying socket.&lt;/p&gt;

&lt;p&gt;And the third and final piece of our request looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let response = request.and_then(|(socket, _)| {
    tokio_core::io::read_to_end(socket, Vec::new())
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The previous &lt;code&gt;request&lt;/code&gt; future is chained again to the final future,
the &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/io/fn.read_to_end.html&#34;&gt;&lt;code&gt;read_to_end&lt;/code&gt;&lt;/a&gt; combinator. This future will read all data from the
&lt;code&gt;socket&lt;/code&gt; provided and place it into the buffer provided (in this case an empty
one), and resolve to the buffer itself once the underlying connection hits EOF.&lt;/p&gt;

&lt;p&gt;Like before, though, reads from the &lt;code&gt;socket&lt;/code&gt; are actually decrypting data
received from the server under the covers, so we&amp;rsquo;re just reading the decrypted
version!&lt;/p&gt;

&lt;p&gt;If we were to return at this point in the program, you might be surprised to see
that nothing happens when it&amp;rsquo;s run! That&amp;rsquo;s because all we&amp;rsquo;ve done so
far is construct a future-based computation, we haven&amp;rsquo;t actually run it. Up to
this point in the program we&amp;rsquo;ve done no I/O, issued no HTTP requests, etc.&lt;/p&gt;

&lt;p&gt;To actually execute our future and drive it to completion we&amp;rsquo;ll need to run the
event loop:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;let (_, data) = core.run(response).unwrap();
println!(&amp;quot;{}&amp;quot;, String::from_utf8_lossy(&amp;amp;data));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we pass our &lt;code&gt;response&lt;/code&gt; future, our entire HTTP request, to
the event loop, &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/reactor/struct.Core.html#method.run&#34;&gt;asking it to resolve the future&lt;/a&gt;. The event loop will
then run until the future has been resolved, returning the result of the future
which in this case is &lt;code&gt;io::Result&amp;lt;(TcpStream, Vec&amp;lt;u8&amp;gt;)&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Note that this &lt;code&gt;core.run(..)&lt;/code&gt; call will block the calling thread until the
future can itself be resolved. This means that &lt;code&gt;data&lt;/code&gt; here has type &lt;code&gt;Vec&amp;lt;u8&amp;gt;&lt;/code&gt;.
We then print it out to stdout as usual.&lt;/p&gt;

&lt;p&gt;Phew! At this point we&amp;rsquo;ve seen futures &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/net/struct.TcpStream.html#method.connect&#34;&gt;initiate a TCP
connection&lt;/a&gt; &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.and_then&#34;&gt;create a chain of computation&lt;/a&gt;,
and &lt;a href=&#34;https://tokio-rs.github.io/tokio-core/tokio_core/io/fn.read_to_end.html&#34;&gt;read data from a socket&lt;/a&gt;. But this is only a hint of what
futures can do, so let&amp;rsquo;s dive more into the traits themselves!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example: a client with proto</title>
      <link>http://aturon.github.io/private/tokio/docs/getting-started/simple-client/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/getting-started/simple-client/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Essential combinators</title>
      <link>http://aturon.github.io/private/tokio/docs/going-deeper/futures-mechanics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/going-deeper/futures-mechanics/</guid>
      <description>

&lt;p&gt;We saw a few of the most important combinators in the
&lt;a href=&#34;../../getting-started/futures&#34;&gt;futures&lt;/a&gt; and
&lt;a href=&#34;../../getting-started/streams-and-sinks&#34;&gt;streams&lt;/a&gt; overviews. Here we&amp;rsquo;ll take a
look at a few more. It&amp;rsquo;s also worth spending some time with the trait
documentation to familiarize yourself with the full range of combinators
available.&lt;/p&gt;

&lt;h3 id=&#34;some-concrete-futures-and-streams&#34;&gt;Some concrete futures and streams&lt;/h3&gt;

&lt;p&gt;Any value can be turned into an immediately complete future. There are a few
functions in the &lt;code&gt;future&lt;/code&gt; module for creating such a future:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/fn.ok.html&#34;&gt;&lt;code&gt;ok&lt;/code&gt;&lt;/a&gt;, which is analogous to &lt;code&gt;Result::Ok&lt;/code&gt;: it treats the value you give it as an immediately successful future.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/fn.err.html&#34;&gt;&lt;code&gt;err&lt;/code&gt;&lt;/a&gt;, which is analogous to &lt;code&gt;Result::Err&lt;/code&gt;: it treats the value you give it as an immediately failed future.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/fn.result.html&#34;&gt;&lt;code&gt;result&lt;/code&gt;&lt;/a&gt;, which lifts a result to an immediately-complete future.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For streams, there are a few equivalents of an &amp;ldquo;immediately ready&amp;rdquo; stream:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/fn.iter.html&#34;&gt;&lt;code&gt;iter&lt;/code&gt;&lt;/a&gt;, which creates a stream that yields the same items as the underlying
iterator. The iterator produces &lt;code&gt;Result&lt;/code&gt; values, and the first error terminates
the stream with that error.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/fn.once.html&#34;&gt;&lt;code&gt;once&lt;/code&gt;&lt;/a&gt;, which creates a single-element stream from a &lt;code&gt;Result&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to these constructors, there&amp;rsquo;s also a function, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/fn.lazy.html&#34;&gt;&lt;code&gt;lazy&lt;/code&gt;&lt;/a&gt;, which
allows you to construct a future given a &lt;em&gt;closure&lt;/em&gt; that will produce that future
later, on demand.&lt;/p&gt;

&lt;h3 id=&#34;intofuture&#34;&gt;IntoFuture&lt;/h3&gt;

&lt;p&gt;A crucial API to know about is the &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.IntoFuture.html&#34;&gt;&lt;code&gt;IntoFuture&lt;/code&gt;&lt;/a&gt; trait, which is a trait for
values that can be converted into futures. Most APIs that you think of as taking
futures actually work with this trait instead. The key reason: the trait is
implemented for &lt;code&gt;Result&lt;/code&gt;, allowing you to return &lt;code&gt;Result&lt;/code&gt; values in many places
that futures are expected.&lt;/p&gt;

&lt;h3 id=&#34;adapters&#34;&gt;Adapters&lt;/h3&gt;

&lt;p&gt;Like &lt;a href=&#34;https://doc.rust-lang.org/std/iter/trait.Iterator.html&#34;&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;, the &lt;code&gt;Future&lt;/code&gt;, &lt;code&gt;Stream&lt;/code&gt; and &lt;code&gt;Sink&lt;/code&gt; traits all come equipped
with a broad range of &amp;ldquo;adapter&amp;rdquo; methods. These methods all consume the receiving
object and return a new, wrapped one. For futures, you can use adapters to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Change the type of a future (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.map&#34;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.map_err&#34;&gt;&lt;code&gt;map_err&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Run another future after one has completed (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.then&#34;&gt;&lt;code&gt;then&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.or_else&#34;&gt;&lt;code&gt;or_else&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Figure out which of two futures resolves first (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.select&#34;&gt;&lt;code&gt;select&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Wait for two futures to both complete (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.join&#34;&gt;&lt;code&gt;join&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Convert to a trait object (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.boxed&#34;&gt;&lt;code&gt;boxed&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Convert unwinding into errors (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.catch_unwind&#34;&gt;&lt;code&gt;catch_unwind&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For streams, there are a large set of adapters, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Many in common with &lt;a href=&#34;https://doc.rust-lang.org/std/iter/trait.Iterator.html&#34;&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;, like &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.map&#34;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.fold&#34;&gt;&lt;code&gt;fold&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.collect&#34;&gt;&lt;code&gt;collect&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.filter&#34;&gt;&lt;code&gt;filter&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.zip&#34;&gt;&lt;code&gt;zip&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.take&#34;&gt;&lt;code&gt;take&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.skip&#34;&gt;&lt;code&gt;skip&lt;/code&gt;&lt;/a&gt; and so on. Note that &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.fold&#34;&gt;&lt;code&gt;fold&lt;/code&gt;&lt;/a&gt; and
&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.collect&#34;&gt;&lt;code&gt;collect&lt;/code&gt;&lt;/a&gt; produce &lt;em&gt;futures&lt;/em&gt;, and hence their result is computed
asynchronously.&lt;/li&gt;
&lt;li&gt;Adapters for sequencing with futures (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.then&#34;&gt;&lt;code&gt;then&lt;/code&gt;&lt;/a&gt;,
&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.and_then&#34;&gt;&lt;code&gt;and_then&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.or_else&#34;&gt;&lt;code&gt;or_else&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Additional adapters for combining streams (&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.merge&#34;&gt;&lt;code&gt;merge&lt;/code&gt;&lt;/a&gt;, &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.select&#34;&gt;&lt;code&gt;select&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;code&gt;Sink&lt;/code&gt; trait currently has fewer adapters; the most important ones were
covered in &lt;a href=&#34;../../getting-started/streams-and-sinks&#34;&gt;the introduction&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Finally, an object that is both a stream and a sink can be broken into separate
stream and sink objects using the &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/stream/trait.Stream.html#method.split&#34;&gt;&lt;code&gt;split&lt;/code&gt;&lt;/a&gt; adapter.&lt;/p&gt;

&lt;p&gt;All adapters are zero-cost, meaning that no memory is allocated internally and
the implementation will optimize to what you would have otherwise written by
hand.&lt;/p&gt;

&lt;h3 id=&#34;error-handling&#34;&gt;Error handling&lt;/h3&gt;

&lt;p&gt;TODO: write this&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;combinators know how to deal with errors. explain &lt;code&gt;then&lt;/code&gt;, &lt;code&gt;and_then&lt;/code&gt;, etc, and
examples of how errors propagate throuh &lt;code&gt;select&lt;/code&gt; and &lt;code&gt;join&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;how to deal with panics&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Returning futures</title>
      <link>http://aturon.github.io/private/tokio/docs/going-deeper/returning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/going-deeper/returning/</guid>
      <description>

&lt;p&gt;When working with futures, one of the first things you&amp;rsquo;re likely to need to do
is to return a &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html&#34;&gt;&lt;code&gt;Future&lt;/code&gt;&lt;/a&gt;. As with &lt;a href=&#34;https://doc.rust-lang.org/std/iter/trait.Iterator.html&#34;&gt;&lt;code&gt;Iterator&lt;/code&gt;&lt;/a&gt;s, however, doing so can be a little tricky.
There are several options, listed from most to least ergonomic:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#trait-objects&#34;&gt;Trait objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#impl-trait&#34;&gt;&lt;code&gt;impl Trait&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#named-types&#34;&gt;Named types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#custom-types&#34;&gt;Custom types&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;trait-objects&#34;&gt;Trait objects&lt;/h3&gt;

&lt;p&gt;First, you always have the option of returning a boxed &lt;a href=&#34;https://doc.rust-lang.org/book/trait-objects.html&#34;&gt;trait object&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn foo() -&amp;gt; Box&amp;lt;Future&amp;lt;Item = u32, Error = io::Error&amp;gt;&amp;gt; {
    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The upside of this strategy is that it&amp;rsquo;s easy to write down (just a [&lt;code&gt;Box&lt;/code&gt;]) and
easy to create. This is also maximally flexible in terms of future changes to
the method as &lt;em&gt;any&lt;/em&gt; type of future can be returned as an opaque, boxed &lt;code&gt;Future&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Note that the &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/trait.Future.html#method.boxed&#34;&gt;&lt;code&gt;boxed&lt;/code&gt;&lt;/a&gt; method returns a &lt;code&gt;BoxFuture&lt;/code&gt;, which is a type alias for
&lt;code&gt;Box&amp;lt;Future + Send&amp;gt;&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn foo() -&amp;gt; BoxFuture&amp;lt;u32, u32&amp;gt; {
    finished(1).boxed()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The downside of this approach is that it requires a runtime allocation when the
future is constructed, and dynamic dispatch when using that future. The &lt;code&gt;Box&lt;/code&gt;
needs to be allocated on the heap and the future itself is then placed
inside. Note, though that this is the &lt;em&gt;only&lt;/em&gt; allocation here, otherwise while
the future is being executed no allocations will be made.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s often possible to mitigate that cost by boxing only at the end of a long
chain of futures you want to return, which entails only a single allocation and
dynamic dispatch for the entire chain.&lt;/p&gt;

&lt;h3 id=&#34;impl-trait&#34;&gt;&lt;code&gt;impl Trait&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;In an ideal world, however, we can have our cake and eat it too with a new
language feature called &lt;a href=&#34;https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md&#34;&gt;&lt;code&gt;impl Trait&lt;/code&gt;&lt;/a&gt;. This language feature will allow, for
example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn add_10&amp;lt;F&amp;gt;(f: F) -&amp;gt; impl Future&amp;lt;Item = i32, Error = F::Error&amp;gt;
    where F: Future&amp;lt;Item = i32&amp;gt;,
{
    f.map(|i| i + 10)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we&amp;rsquo;re indicating that the return type is &amp;ldquo;something that implements
&lt;code&gt;Future&lt;/code&gt;&amp;rdquo; with the given associated types. Other than that we just use the
future combinators as we normally would.&lt;/p&gt;

&lt;p&gt;The upsides to this approach are that it is zero overhead with no &lt;code&gt;Box&lt;/code&gt;
necessary, it&amp;rsquo;s maximally flexible to future implementations as the actual
return type is hidden, and it&amp;rsquo;s ergonomic to write as it&amp;rsquo;s similar to the nice
&lt;code&gt;Box&lt;/code&gt; example above.&lt;/p&gt;

&lt;p&gt;The downside to this approach is only that it&amp;rsquo;s not on stable Rust yet. As of
the time of this writing &lt;a href=&#34;https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md&#34;&gt;&lt;code&gt;impl Trait&lt;/code&gt;&lt;/a&gt; is available on nightly, but will likely
take some time to stabilize. The good news, however, is that as soon as &lt;code&gt;impl
Trait&lt;/code&gt; hits stable Rust all crates using futures can immediately benefit. It
should be a backwards-compatible extension to change return types from &lt;code&gt;Box&lt;/code&gt; to
&lt;a href=&#34;https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md&#34;&gt;&lt;code&gt;impl Trait&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;named-types&#34;&gt;Named types&lt;/h3&gt;

&lt;p&gt;If you&amp;rsquo;d like to not return a &lt;code&gt;Box&lt;/code&gt;, but want to stick with stable Rust, another
option is to write the return type directly:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn add_10&amp;lt;F&amp;gt;(f: F) -&amp;gt; Map&amp;lt;F, fn(i32) -&amp;gt; i32&amp;gt;
    where F: Future&amp;lt;Item = i32&amp;gt;,
{
    fn do_map(i: i32) -&amp;gt; i32 { i + 10 }
    f.map(do_map)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we name the return type exactly as the compiler sees it. The &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/struct.Map.html&#34;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt;
function returns the &lt;a href=&#34;https://docs.rs/futures/0.1/futures/future/struct.Map.html&#34;&gt;&lt;code&gt;Map&lt;/code&gt;&lt;/a&gt; struct which internally contains the future and the
function to perform the map.&lt;/p&gt;

&lt;p&gt;The upside to this approach is that it doesn&amp;rsquo;t have the runtime overhead of
&lt;code&gt;Box&lt;/code&gt; from before, and works on stable Rust.&lt;/p&gt;

&lt;p&gt;The downside, however, is that it&amp;rsquo;s often quite difficult to name the type.
Sometimes the types can get quite large or be unnameable altogether. Here we&amp;rsquo;re
using a function pointer (&lt;code&gt;fn(i32) -&amp;gt; i32&lt;/code&gt;) but we would ideally use a closure.
Unfortunately the return type cannot name the closure, for now. It also leads to
very verbose signatures, and leaks implementation details to clients.&lt;/p&gt;

&lt;h3 id=&#34;custom-types&#34;&gt;Custom types&lt;/h3&gt;

&lt;p&gt;Finally, you can wrap the concrete return type in a new type, and implement
future for it. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;struct MyFuture {
    inner: Oneshot&amp;lt;i32&amp;gt;,
}

fn foo() -&amp;gt; MyFuture {
    let (tx, rx) = oneshot();
    // ...
    MyFuture { inner: tx }
}

impl Future for MyFuture {
    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example we&amp;rsquo;re returning a custom type, &lt;code&gt;MyFuture&lt;/code&gt;, and we implement the
&lt;code&gt;Future&lt;/code&gt; trait directly for it. This implementation leverages an underlying
&lt;code&gt;Oneshot&amp;lt;i32&amp;gt;&lt;/code&gt;, but any other kind of protocol can also be implemented here as
well.&lt;/p&gt;

&lt;p&gt;The upside to this approach is that it won&amp;rsquo;t require a &lt;code&gt;Box&lt;/code&gt; allocation and it&amp;rsquo;s
still maximally flexible. The implementation details of &lt;code&gt;MyFuture&lt;/code&gt; are hidden to
the outside world so it can change without breaking others.&lt;/p&gt;

&lt;p&gt;The downside to this approach, however, is that this is the least ergonomic way
to return futures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The futures-rs model in depth</title>
      <link>http://aturon.github.io/private/tokio/docs/going-deeper/futures-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/going-deeper/futures-model/</guid>
      <description>

&lt;p&gt;At this point, we&amp;rsquo;re ready to dig into the implementation details for futures,
streams and sinks. You&amp;rsquo;ll be armed with the tools needed to write your own
direct implementations of these traits, rather than relying solely on the
combinator API.&lt;/p&gt;

&lt;p&gt;All three abstractions rest on the same core ideas:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Making progress on async computations by &lt;em&gt;demand&lt;/em&gt;, rather than letting them
proceed on their own.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Encapsulating async computations into &lt;em&gt;tasks&lt;/em&gt;, which are essentially
lightweight threads (and the basic unit of concurrency in &lt;code&gt;futures-rs&lt;/code&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To understand both of these points, we&amp;rsquo;ll walk through the story with a focus on
futures. We&amp;rsquo;ll then touch on streams and sinks at the end.&lt;/p&gt;

&lt;h2 id=&#34;revisiting-the-future-trait&#34;&gt;Revisiting the &lt;code&gt;Future&lt;/code&gt; trait&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s take another look at the core definition of the &lt;code&gt;Future&lt;/code&gt; trait, this time
paying more attention to the required &lt;code&gt;poll&lt;/code&gt; method:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;trait Future {
    // The type of value that the future yields on successful completion.
    type Item;

    // The type of value that the future yields on failure.
    type Error;

    // The only required method, which attempts to complete the future.
    fn poll(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;Self::Item, Self::Error&amp;gt;;

    // ... and the various defaulted method
}

type Poll&amp;lt;T, E&amp;gt; = Result&amp;lt;Async&amp;lt;T&amp;gt;, E&amp;gt;;

enum Async&amp;lt;T&amp;gt; {
    /// Represents that a value is immediately ready.
    Ready(T),

    /// Represents that a value is not ready yet, but may be so later.
    NotReady,
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;poll&lt;/code&gt; method attempts to make progress on the future, for example
retrieving bytes from a network socket if they&amp;rsquo;re required and are available.
The method has several outcomes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ok(Async::Ready(t))&lt;/code&gt;: successful completion with the value &lt;code&gt;t&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ok(Async::NotReady)&lt;/code&gt;: could not currently complete. (This is an
abstraction of &lt;code&gt;EWOULDBLOCK&lt;/code&gt; from the Unix world).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Err(e)&lt;/code&gt;: completed with an error &lt;code&gt;e&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After completion of any kind, it is a contract violation to poll a future
again. (You can use &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.fuse&#34;&gt;&lt;code&gt;fuse&lt;/code&gt;&lt;/a&gt; to work around that if need be.)&lt;/p&gt;

&lt;p&gt;In the async I/O world, this kind of interface is sometimes referred to as
&lt;em&gt;readiness-based&lt;/em&gt;, because events are signaled based on &amp;ldquo;readiness&amp;rdquo; of
operations (e.g. bytes on a socket being ready) followed by an attempt to
complete an operation;
&lt;a href=&#34;http://man7.org/linux/man-pages/man7/epoll.7.html&#34;&gt;Linux&amp;rsquo;s epoll&lt;/a&gt; is based on
this model. You can read more about the tradeoffs for this design in
&lt;a href=&#34;http://aturon.github.io/blog/2016/09/07/futures-design/&#34;&gt;the blog post that describes it&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But there&amp;rsquo;s a big question: after &lt;code&gt;NotReady&lt;/code&gt; is returned, who polls the future,
and when do they do so?&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a concrete example. If a future is attempting to read bytes from a
socket, that socket may not be ready for reading, in which case the future can
return &lt;code&gt;NotReady&lt;/code&gt;. &lt;em&gt;Somehow&lt;/em&gt;, we must arrange for the future to later be &amp;ldquo;woken
up&amp;rdquo; (by calling &lt;code&gt;poll&lt;/code&gt;) once the socket becomes ready. That kind of wakeup is
the job of the &lt;a href=&#34;../../getting-started/reactor&#34;&gt;event loop&lt;/a&gt;. But now we need some
way to connect the signal at the event loop back to continuing to poll the
future.&lt;/p&gt;

&lt;p&gt;The solution forms the other main component of the design: tasks.&lt;/p&gt;

&lt;h3 id=&#34;the-cornerstone-tasks&#34;&gt;The cornerstone: tasks&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;A &lt;em&gt;task&lt;/em&gt; is a future that is being executed&lt;/strong&gt;. That future is almost always
made up of a chain of other futures, like the following one:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;id_rpc(&amp;amp;my_server).and_then(|id| {
    get_row(id)
}).map(|row| {
    json::encode(row)
}).and_then(|encoded| {
    write_string(my_socket, encoded)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key point is that there&amp;rsquo;s a difference between functions like &lt;code&gt;and_then&lt;/code&gt;,
&lt;code&gt;map&lt;/code&gt; and &lt;code&gt;join&lt;/code&gt;, which &lt;em&gt;combine&lt;/em&gt; futures into bigger futures, and functions that
&lt;em&gt;execute&lt;/em&gt; futures, like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;wait&lt;/code&gt; method, which simply runs the future as a task pinned to the
current thread, blocking that thread until a result is produced and returned.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;code&gt;spawn&lt;/code&gt; method on a thread pool, which launches a future as an independent
task on the pool.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These execution functions create a task that contains the future and is
responsible for polling it. In the case of &lt;code&gt;wait&lt;/code&gt;, polling takes place
immediately; for &lt;code&gt;spawn&lt;/code&gt;, polling happens once the task is &lt;em&gt;scheduled&lt;/em&gt; onto a
worker thread.&lt;/p&gt;

&lt;p&gt;However polling begins, if any of the interior futures produced a &lt;code&gt;NotReady&lt;/code&gt;
result, it can grind the whole task to a haltâ€”the task may need to wait for some
event to occur before it can continue. In synchronous I/O, this is where a
thread would block. Tasks provide an equivalent to this model: the task &amp;ldquo;blocks&amp;rdquo;
by yielding back to its executor, &lt;strong&gt;after installing itself as a callback for
the events it&amp;rsquo;s waiting on&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Returning to the example of reading from a socket, on a &lt;code&gt;NotReady&lt;/code&gt; result the
task can be added to the event loop&amp;rsquo;s dispatch table, so that it will be woken
up when the socket becomes ready, at which point it will re-&lt;code&gt;poll&lt;/code&gt; its future.
Crucially, though, the task instance stays fixed for the lifetime of the future
it is executingâ€”&lt;strong&gt;so no allocation is needed to create or install this callback&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Completing the analogy with threads, tasks provide a &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/fn.park.html&#34;&gt;&lt;code&gt;park&lt;/code&gt;&lt;/a&gt;/&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/fn.park.html&#34;&gt;&lt;code&gt;unpark&lt;/code&gt;&lt;/a&gt; API for
&amp;ldquo;blocking&amp;rdquo; and wakeup:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;/// Returns a handle to the current task to call unpark at a later date.
fn park() -&amp;gt; Task;

impl Task {
    /// Indicate that the task should attempt to poll its future in a timely fashion.
    fn unpark(&amp;amp;self);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Blocking a future is a matter of using &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/fn.park.html&#34;&gt;&lt;code&gt;park&lt;/code&gt;&lt;/a&gt; to get a handle to its task,
putting the resulting &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/struct.Task.html&#34;&gt;&lt;code&gt;Task&lt;/code&gt;&lt;/a&gt; in some wakeup queue for the event of interest,
and returning &lt;code&gt;NotReady&lt;/code&gt;. When the event of interest occurs, the &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/struct.Task.html&#34;&gt;&lt;code&gt;Task&lt;/code&gt;&lt;/a&gt; handle
can be used to wake back up the task, e.g. by rescheduling it for execution on a
thread pool. The precise mechanics of &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/fn.park.html&#34;&gt;&lt;code&gt;park&lt;/code&gt;&lt;/a&gt;/&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/fn.park.html&#34;&gt;&lt;code&gt;unpark&lt;/code&gt;&lt;/a&gt; vary by task executor.&lt;/p&gt;

&lt;p&gt;In a way, the task model is an instance of &amp;ldquo;green&amp;rdquo; (aka lightweight) threading:
we schedule a potentially large number of asynchronous tasks onto a much smaller
number of real OS threads, and most of those tasks are blocked on some event
most of the time. There&amp;rsquo;s an essential difference from Rust&amp;rsquo;s
&lt;a href=&#34;https://github.com/aturon/rfcs/blob/remove-runtime/active/0000-remove-runtime.md&#34;&gt;old green threading model&lt;/a&gt;,
however: &lt;strong&gt;tasks do not require their own stack&lt;/strong&gt;. In fact, all of the data
needed by a task is contained within its future. That means we can neatly
sidestep problems of dynamic stack growth and stack swapping, giving us truly
lightweight tasks without any runtime system implications.&lt;/p&gt;

&lt;p&gt;Perhaps surprisingly, &lt;strong&gt;the future within a task compiles down to a state
machine&lt;/strong&gt;, so that every time the task wakes up to continue polling, it
continues execution from the current stateâ€”working just like hand-rolled code
based on &lt;a href=&#34;http://github.com/carllerche/mio&#34;&gt;mio&lt;/a&gt;. This point is most easily seen
by example, so let&amp;rsquo;s revisit &lt;code&gt;join&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;example-sketching-the-join-combinator&#34;&gt;Example: sketching the &lt;code&gt;join&lt;/code&gt; combinator&lt;/h3&gt;

&lt;p&gt;To implement the &lt;code&gt;join&lt;/code&gt; combinator, we&amp;rsquo;ll introduce a new concrete type, &lt;code&gt;Join&lt;/code&gt;,
that tracks the necessary state:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn join&amp;lt;F: Future, G: Future&amp;gt;(f: F, g: G) -&amp;gt; Join&amp;lt;F, G&amp;gt; {
    Join::BothRunning(f, g)
}

enum Join&amp;lt;F: Future, G: Future&amp;gt; {
    BothRunning(F, G),
    FirstDone(F::Item, G),
    SecondDone(F, G::Item),
    Done,
}

impl&amp;lt;F, G&amp;gt; Future for Join&amp;lt;F, G&amp;gt; where F: Future, G: Future {
    type Item = (F::Item, G::Item);

    fn poll(&amp;amp;mut self) -&amp;gt; Async&amp;lt;Self::Item&amp;gt; {
        // navigate the state machine
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first thing to notice is that &lt;code&gt;Join&lt;/code&gt; is an &lt;em&gt;enum&lt;/em&gt;, whose variants represent
states in the &amp;ldquo;join state machine&amp;rdquo;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BothRunning&lt;/code&gt;: the two underlying futures are both still executing.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FirstDone&lt;/code&gt;: the first future has yielded a value, but the second is still executing.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SecondDone&lt;/code&gt;: the second future has yielded a value, but the first is still executing.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Done&lt;/code&gt;: both futures completed, and their values have been returned.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recall that enums in Rust are represented without requiring any pointers or heap
allocation; instead, the size of the enum is the size of the largest
variant. That&amp;rsquo;s exactly what we want&amp;mdash;that size represents the &amp;ldquo;high water mark&amp;rdquo;
of this little state machine.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;poll&lt;/code&gt; method here will attempt to make progress through the state machine
by &lt;code&gt;poll&lt;/code&gt;ing the underlying futures as appropriate.&lt;/p&gt;

&lt;p&gt;Recall that the aim of &lt;code&gt;join&lt;/code&gt; is to allow its two futures to proceed
concurrently, racing to finish. For example, the two futures might each
represent subtasks running in parallel on a thread pool. When those subtasks are
still running, &lt;code&gt;poll&lt;/code&gt;ing their futures will return &lt;code&gt;NotReady&lt;/code&gt;, effectively
&amp;ldquo;blocking&amp;rdquo; the &lt;code&gt;Join&lt;/code&gt; future, while stashing a handle to the ambient &lt;code&gt;Task&lt;/code&gt; for
waking it back up when they finish. The two subtasks can then race to &lt;em&gt;wake up&lt;/em&gt;
the &lt;code&gt;Task&lt;/code&gt;, but that&amp;rsquo;s fine: &lt;strong&gt;the &lt;code&gt;unpark&lt;/code&gt; method for waking a task is
threadsafe, and guarantees that the task will &lt;code&gt;poll&lt;/code&gt; its future at least once
after any &lt;code&gt;unpark&lt;/code&gt; call&lt;/strong&gt;. Thus, synchronization is handled once and for all at
the task level, without requiring combinators like &lt;code&gt;join&lt;/code&gt; to allocate or handle
synchronization themselves.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;You may have noticed that &lt;code&gt;poll&lt;/code&gt; takes &lt;code&gt;&amp;amp;mut self&lt;/code&gt;, which means that a given
future cannot be &lt;code&gt;poll&lt;/code&gt;ed concurrentlyâ€”the future has unique access to its
contents while polling. The &lt;code&gt;unpark&lt;/code&gt; synchronization guarantees it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One final point. Combinators like &lt;code&gt;join&lt;/code&gt; embody &amp;ldquo;small&amp;rdquo; state machines, but
because some of those states involve additional futures, they allow additional
state machines to be &lt;em&gt;nested&lt;/em&gt;. In other words, &lt;code&gt;poll&lt;/code&gt;ing one of the underlying
futures for &lt;code&gt;join&lt;/code&gt; may involve stepping through &lt;em&gt;its&lt;/em&gt; state machine, before
taking steps in the &lt;code&gt;Join&lt;/code&gt; state machine. &lt;strong&gt;The fact that the use of the
&lt;code&gt;Future&lt;/code&gt; trait does not entail heap allocation or dynamic dispatch is key to
making this work efficiently.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In general, the &amp;ldquo;big&amp;rdquo; future being run by a taskâ€”made up of a large chain of
futures connected by combinators&amp;mdash;embodies a &amp;ldquo;big&amp;rdquo; nested state machine in just
this way. Once more, Rust&amp;rsquo;s enum representation means that the space required is
the size of the state in the &amp;ldquo;big&amp;rdquo; machine with the largest footprint. The space
for this &amp;ldquo;big&amp;rdquo; future is allocated in &lt;em&gt;one shot&lt;/em&gt; by the task, either on the
stack (for the &lt;code&gt;wait&lt;/code&gt; executor) or on the heap (for &lt;code&gt;spawn&lt;/code&gt;). After all, the
data has to live &lt;em&gt;somewhere&lt;/em&gt;&amp;mdash;but the key is to avoid constant allocations as
the state machine progresses, by instead making space for the entire thing up
front.&lt;/p&gt;

&lt;h2 id=&#34;futures-at-scale&#34;&gt;Futures at scale&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve seen the basics mechaics of futures, but there are a number of concerns
about &lt;em&gt;robustness&lt;/em&gt; that we also want to cover. It turns out that these concerns
are addressed naturally by the demand-driven &lt;code&gt;poll&lt;/code&gt; model. Let&amp;rsquo;s take a look at
a few of the most important.&lt;/p&gt;

&lt;h3 id=&#34;cancellation&#34;&gt;Cancellation&lt;/h3&gt;

&lt;p&gt;Futures are often used to represent substantial work that is running
concurrently. Sometimes it will become clear that this work is no longer
needed, perhaps because a timeout occurred, or the client closed a connection,
or the needed answer was found in some other way.&lt;/p&gt;

&lt;p&gt;In situations like these, you want some form of &lt;em&gt;cancellation&lt;/em&gt;: the ability to
tell a future to stop executing because you&amp;rsquo;re no longer interested in its
result.&lt;/p&gt;

&lt;p&gt;In the demand-driven model, cancellation largely &amp;ldquo;falls out&amp;rdquo;. All you have to do
is stop polling the future, instead dropping it. And doing so is usually a
natural consequence of nested state machines like &lt;code&gt;Join&lt;/code&gt;. Futures whose
computation requires some special effort to cancel (such as canceling an RPC
call) can provide this logic as part of their &lt;code&gt;Drop&lt;/code&gt; implementation.&lt;/p&gt;

&lt;h3 id=&#34;backpressure&#34;&gt;Backpressure&lt;/h3&gt;

&lt;p&gt;Another essential aspect of at-scale use of futures (and streams and sinks) is
&lt;em&gt;backpressure&lt;/em&gt;: the ability of an overloaded component in one part of a system
to slow down input from other components. For example, if a server has a backlog
of database transactions for servicing outstanding requests, it should slow down
taking new requests.&lt;/p&gt;

&lt;p&gt;Like cancellation, backpressure largely falls out of our model for futures and
streams. That&amp;rsquo;s because tasks can be indefinitely &amp;ldquo;blocked&amp;rdquo; by a future/stream
returning &lt;code&gt;NotReady&lt;/code&gt;, and notified to continue polling at a later time. For the
example of database transactions, if enqueuing a transaction is itself
represented as a future, the database service can return &lt;code&gt;NotReady&lt;/code&gt; to slow down
requests. Often, such &lt;code&gt;NotReady&lt;/code&gt; results cascade backward through a system,
e.g. allowing backpressure to flow from the database service back to a
particular client connection then back to the overall connection manager. Such
cascades are a natural consequence of the demand-driven model.&lt;/p&gt;

&lt;h3 id=&#34;communicating-the-cause-of-a-wakeup&#34;&gt;Communicating the cause of a wakeup&lt;/h3&gt;

&lt;p&gt;If you&amp;rsquo;re familiar with interfaces like
&lt;a href=&#34;http://man7.org/linux/man-pages/man7/epoll.7.html&#34;&gt;epoll&lt;/a&gt;, you may have noticed
something missing from the &lt;code&gt;park&lt;/code&gt;/&lt;code&gt;unpark&lt;/code&gt; model: it provides no way for a task
to know &lt;em&gt;why&lt;/em&gt; it was woken up.&lt;/p&gt;

&lt;p&gt;That can be a problem for certain kinds futures that involve polling a large
number of other futures concurrentlyâ€”you don&amp;rsquo;t want to have to re-poll
&lt;em&gt;everything&lt;/em&gt; to discover which sub-future is actually able to make progress.&lt;/p&gt;

&lt;p&gt;To deal with this problem, the library offers a kind of &amp;ldquo;epoll for everyone&amp;rdquo;:
the ability to associate &amp;ldquo;unpark events&amp;rdquo; with a given &lt;code&gt;Task&lt;/code&gt; handle. That is,
there may be various handles to the same task floating around, all of which can
be used to wake the task up, but each of which carries different unpark events.
When woken, the future within the task can inspect these unpark events to
determine what happened. See &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/task/fn.with_unpark_event.html&#34;&gt;&lt;code&gt;with_unpark_event&lt;/code&gt;&lt;/a&gt; for more detail.&lt;/p&gt;

&lt;h2 id=&#34;streams-and-sinks&#34;&gt;Streams and sinks&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve focused primarily on futures above, but streams and sinks work largely the
same way.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with streams. They have a &lt;code&gt;poll&lt;/code&gt; function that is very similar to
the one for futures:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;fn poll(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;Option&amp;lt;Self::Item&amp;gt;, Self::Error&amp;gt;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The only difference is that the return value is an &lt;code&gt;Option&lt;/code&gt;, which works much
like with &lt;code&gt;Iterator&lt;/code&gt;. The stream is considered terminated after returning either
an error, or completing with &lt;code&gt;None&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Sinks are more interesting:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;trait Sink {
    // The type of value that the sink accepts.
    type SinkItem;

    // The type of value produced by the sink when an error occurs.
    type SinkError;

    // The analog to `poll`, used for sending and then flushing items.
    fn start_send(&amp;amp;mut self, item: Self::SinkItem)
                  -&amp;gt; StartSend&amp;lt;Self::SinkItem, Self::SinkError&amp;gt;;
    fn poll_complete(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;(), Self::SinkError&amp;gt;;

    // ... and lots of default methods, as usual
}

type StartSend&amp;lt;T, E&amp;gt; = Result&amp;lt;AsyncSink&amp;lt;T&amp;gt;, E&amp;gt;;

enum AsyncSink&amp;lt;T&amp;gt; {
    /// The `start_send` attempt succeeded, so the sending process has
    /// *started*; you muse use `Sink::poll_complete` to drive the send
    /// to completion.
    Ready,

    /// The `start_send` attempt failed due to the sink being full. The
    /// value being sent is returned, and the current `Task` will be
    /// automatically notified again once the sink has room.
    NotReady(T),
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key thing that makes sinks different is the potential for buffering. That
means that sending data into a sink is a two-step process: initiating the send,
which may buffer the data, and flushing any buffers to complete the
send. Following our async model, flushing requires repeated polling to drive
toward success, much like a future.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/sink/trait.Sink.html#tymethod.start_send&#34;&gt;&lt;code&gt;start_send&lt;/code&gt;&lt;/a&gt; method attempts to initiate a send into the sink. If the sink
is ready to accept more data (e.g., it has free buffer space), it will return
&lt;code&gt;Ok(Ready)&lt;/code&gt;. If it cannot currently accept data, it will return
&lt;code&gt;Ok(NotReady(m))&lt;/code&gt;, where &lt;code&gt;m&lt;/code&gt; is the message you were trying to send. Just as
with &lt;code&gt;Async::NotReady&lt;/code&gt;, this result means that the current task is
&lt;em&gt;automatically&lt;/em&gt; scheduled to be woken up when the sink becomes ready to take
more data.&lt;/p&gt;

&lt;p&gt;After a send is successfully initiated, at some point later the sink should be
flushed (and, in particular, before it is dropped). For that, you use
&lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/sink/trait.Sink.html#tymethod.poll_complete&#34;&gt;&lt;code&gt;poll_complete&lt;/code&gt;&lt;/a&gt;, whose signature matches that of a future that returns &lt;code&gt;()&lt;/code&gt; on
completion (i.e., when the data has been entirely flushed).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Synchronization</title>
      <link>http://aturon.github.io/private/tokio/docs/going-deeper/synchronization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/going-deeper/synchronization/</guid>
      <description>

&lt;p&gt;The &lt;code&gt;futures-rs&lt;/code&gt; crate comes equipped with a small &lt;em&gt;futures-aware
synchronization&lt;/em&gt; toolkit, in the &lt;a href=&#34;https://docs.rs/futures/0.1.7/futures/sync/index.html&#34;&gt;&lt;code&gt;sync&lt;/code&gt; module&lt;/a&gt;. The abstractions here can be
used to coordinate concurrent interactions between futures, streams, or sinks. Like the rest of the futures library, these APIs are non-blocking; they work with the &lt;a href=&#34;../futures-model&#34;&gt;&lt;code&gt;futures-rs&lt;/code&gt; task system&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;oneshot&#34;&gt;Oneshot&lt;/h2&gt;

&lt;p&gt;TODO: introductory text&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-rust&#34;&gt;extern crate futures;

use std::thread;
use futures::Future;

fn expensive_computation() -&amp;gt; u32 {
    // ...
    200
}

fn main() {
    let (tx, rx) = futures::oneshot();

    thread::spawn(move || {
        tx.complete(expensive_computation());
    });

    let rx = rx.map(|x| x + 3);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we can see that the &lt;a href=&#34;https://docs.rs/futures/0.1/futures/sync/fn.oneshot.html&#34;&gt;&lt;code&gt;oneshot&lt;/code&gt;&lt;/a&gt; function returns two halves (like
&lt;a href=&#34;https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html&#34;&gt;&lt;code&gt;mpsc::channel&lt;/code&gt;&lt;/a&gt;). The first half, &lt;code&gt;tx&lt;/code&gt; (&amp;ldquo;transmitter&amp;rdquo;), is of type &lt;a href=&#34;https://docs.rs/futures/0.1/futures/struct.Complete.html&#34;&gt;&lt;code&gt;Complete&lt;/code&gt;&lt;/a&gt;
and is used to complete the oneshot, providing a value to the future on the
other end. The &lt;a href=&#34;https://docs.rs/futures/0.1/futures/struct.Complete.html#method.complete&#34;&gt;&lt;code&gt;Complete::complete&lt;/code&gt;&lt;/a&gt; method will transmit the value to the
receiving end.&lt;/p&gt;

&lt;p&gt;The second half, &lt;code&gt;rx&lt;/code&gt; (&amp;ldquo;receiver&amp;rdquo;), is of type &lt;a href=&#34;https://docs.rs/futures/0.1/futures/struct.Oneshot.html&#34;&gt;&lt;code&gt;Oneshot&lt;/code&gt;&lt;/a&gt; which is
a type that implements the [&lt;code&gt;Future&lt;/code&gt;] trait. The &lt;code&gt;Item&lt;/code&gt; type is &lt;code&gt;T&lt;/code&gt;, the type
of the oneshot.  The &lt;code&gt;Error&lt;/code&gt; type is &lt;a href=&#34;https://docs.rs/futures/0.1/futures/struct.Canceled.html&#34;&gt;&lt;code&gt;Canceled&lt;/code&gt;&lt;/a&gt;, which happens when the
&lt;a href=&#34;https://docs.rs/futures/0.1/futures/struct.Complete.html&#34;&gt;&lt;code&gt;Complete&lt;/code&gt;&lt;/a&gt; half is dropped without completing the computation.&lt;/p&gt;

&lt;p&gt;This concrete implementation of &lt;code&gt;Future&lt;/code&gt; can be used (as shown here) to
communicate values across threads. Each half implements the &lt;code&gt;Send&lt;/code&gt; trait and is
a separately owned entity to get passed around. It&amp;rsquo;s generally not recommended
to make liberal use of this type of future, however; the combinators above or
other forms of base futures should be preferred wherever possible.&lt;/p&gt;

&lt;h2 id=&#34;channels&#34;&gt;Channels&lt;/h2&gt;

&lt;p&gt;TODO: update this text&lt;/p&gt;

&lt;p&gt;For the [&lt;code&gt;Stream&lt;/code&gt;] trait, a similar primitive is available, &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/fn.channel.html&#34;&gt;&lt;code&gt;channel&lt;/code&gt;&lt;/a&gt;. This
type also has two halves, where the sending half is used to send messages and
the receiving half implements &lt;code&gt;Stream&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The channel&amp;rsquo;s &lt;a href=&#34;https://docs.rs/futures/0.1/futures/stream/struct.Sender.html&#34;&gt;&lt;code&gt;Sender&lt;/code&gt;&lt;/a&gt; type differs from the standard library&amp;rsquo;s in an
important way: when a value is sent to the channel it consumes the sender,
returning a future that will resolve to the original sender only once the sent
value is consumed. This creates backpressure so that a producer won&amp;rsquo;t be able to
make progress until the consumer has caught up.&lt;/p&gt;

&lt;h2 id=&#34;bilock&#34;&gt;Bilock&lt;/h2&gt;

&lt;p&gt;TODO: write this section&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Low-level I/O using core</title>
      <link>http://aturon.github.io/private/tokio/docs/going-deeper/core-low-level/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://aturon.github.io/private/tokio/docs/going-deeper/core-low-level/</guid>
      <description>&lt;p&gt;TODO: talk about working with &lt;code&gt;Read&lt;/code&gt; and &lt;code&gt;Write&lt;/code&gt; etc&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Some text from Alex&amp;rsquo;s draft&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Additionally the I/O objects are also &amp;ldquo;futures-aware&amp;rdquo; in how they interact with
a future&amp;rsquo;s task. Whenever a &amp;ldquo;would block&amp;rdquo; error is returned, then like with
futures returning &lt;code&gt;Async::NotReady&lt;/code&gt;, the current task is scheduled to get woken
up when the I/O object is otherwise ready. This means that you can typically do
I/O as usual in a future, return &lt;code&gt;NotReady&lt;/code&gt; when you see &amp;ldquo;would block&amp;rdquo;, and
you&amp;rsquo;ll get automatically retried when data is otherwise available. Note that
this importantly means that I/O cannot be performed off the task of a future,
similarly to how &lt;code&gt;Future::poll&lt;/code&gt; cannot be called off the task of a future.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>